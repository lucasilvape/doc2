{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#objetivo","title":"Objetivo","text":"<p>Este reposit\u00f3rio cont\u00e9m pipelines de ETL (Extract, Transform, Load) que extraem dados de collections MongoDB e os inserem em tabelas Postgres. </p> <p>Prop\u00f3sito: Todos os produtos seguem o mesmo padr\u00e3o arquitetural:</p> <ul> <li>Extra\u00e7\u00e3o: Dados brutos de duas collections MongoDB principais</li> <li>Collection de implementations/infos (dados do produto/ap\u00f3lice)</li> <li> <p>Collection de installments/parcelas (dados de parcelamento)</p> </li> <li> <p>Transforma\u00e7\u00e3o: Limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es e merge entre collections</p> </li> <li> <p>Carga: Inser\u00e7\u00e3o dos dados processados em tabelas Postgres espec\u00edficas por produto</p> </li> </ul> <p>Suporte a modos de atualiza\u00e7\u00e3o: Incremental (baseado em modifica\u00e7\u00f5es recentes) ou Full, com escolha autom\u00e1tica via modo DIN\u00c2MICO.</p>"},{"location":"#como-executar","title":"Como executar","text":"<p>Este trecho \u00e9 comum a todos os produtos/pipelines deste reposit\u00f3rio. Use-o como refer\u00eancia r\u00e1pida para rodar qualquer pipeline localmente.</p> <ol> <li>Clone o reposit\u00f3rio:</li> </ol> <pre><code>git clone https://github.com/KovrSeguradoraBI/PIPELINES_MONGODB.git\n</code></pre> <ol> <li>Entre na pasta e instale depend\u00eancias (Poetry):</li> </ol> <pre><code>cd PIPELINES_MONGODB\npoetry install\n</code></pre> <p>(opcional) criar venv dentro do projeto:</p> <pre><code>poetry config virtualenvs.in-project true\n</code></pre> <ol> <li> <p>Ajuste vari\u00e1veis de ambiente conforme <code>.env.example</code>.</p> </li> <li> <p>Exemplo de execu\u00e7\u00e3o (modo <code>DINAMICO</code>):</p> </li> </ol> <pre><code>poetry run python main_&lt;produto&gt;.py --tp_atualizacao DINAMICO\n</code></pre> <p>Observa\u00e7\u00e3o</p> <p>Cada produto tem seu <code>main_&lt;produto&gt;.py</code>.</p>"},{"location":"#arquitetura-geral-dos-pipelines","title":"Arquitetura Geral dos Pipelines","text":""},{"location":"#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Todos os produtos seguem o mesmo padr\u00e3o arquitetural de ETL (Extract, Transform, Load):</p> <ul> <li> <p>Fonte: MongoDB (produ\u00e7\u00e3o/homologa\u00e7\u00e3o) com duas collections principais</p> </li> <li> <p>Destino: Tabela Postgres espec\u00edfica por produto</p> </li> <li> <p>Estrutura: Uma collection de \"implementa\u00e7\u00e3o/infos\" + uma collection de \"parcelas\"</p> </li> </ul>"},{"location":"#fluxo-padrao-de-processamento","title":"Fluxo Padr\u00e3o de Processamento","text":""},{"location":"#1-geracao-de-base-gerar_base_para_busca","title":"1. Gera\u00e7\u00e3o de Base (<code>gerar_base_para_busca</code>)","text":"<ul> <li>Filtra bilhetes por data de cria\u00e7\u00e3o com dias retroativos configur\u00e1veis</li> <li>Suporta 4 modos de atualiza\u00e7\u00e3o:</li> <li><code>DIARIO</code>: processa bilhetes de uma data espec\u00edfica (formato <code>yyyy-mm-dd</code>)</li> <li><code>INCREMENTAL</code>: processa apenas bilhetes modificados nos \u00faltimos N dias</li> <li><code>FULL</code>: processa todos os bilhetes, independente de modifica\u00e7\u00f5es</li> <li><code>DINAMICO</code>: escolhe automaticamente entre FULL ou INCREMENTAL baseado no percentual de modifica\u00e7\u00f5es</li> </ul>"},{"location":"#2-geracao-de-queries","title":"2. Gera\u00e7\u00e3o de Queries","text":"<ul> <li><code>gerar_querys_buscar_infos()</code>: cria pipelines MongoDB para buscar dados de implementa\u00e7\u00e3o</li> <li><code>gerar_querys_buscar_parcelas()</code>: cria pipelines MongoDB para buscar dados de parcelas</li> <li>Divide consultas em lotes configur\u00e1veis para otimizar performance</li> </ul>"},{"location":"#3-busca-e-transformacao-buscar_dados_bilhetes","title":"3. Busca e Transforma\u00e7\u00e3o (<code>buscar_dados_bilhetes</code>)","text":"<ul> <li>Busca: <code>buscar_infos_bilhetes()</code> + <code>buscar_parcelas()</code></li> <li>Merge: jun\u00e7\u00e3o entre infos e parcelas usando chaves UUID espec\u00edficas</li> <li>Transforma\u00e7\u00e3o: <code>tratamentos_df()</code> aplica limpeza, convers\u00f5es de tipos e valida\u00e7\u00f5es</li> <li>Valida\u00e7\u00e3o: schema Pandera espec\u00edfico por produto</li> </ul>"},{"location":"#4-processamento-etl-tratamentos_df","title":"4. Processamento ETL (<code>tratamentos_df</code>)","text":"<ul> <li>Strings: limpeza e normaliza\u00e7\u00e3o de campos texto</li> <li>N\u00fameros: convers\u00e3o com <code>pd.to_numeric(errors='coerce')</code></li> <li>Datas: cria\u00e7\u00e3o de campos derivados padronizados</li> <li>Normaliza\u00e7\u00e3o: renomea\u00e7\u00e3o de todas as colunas para min\u00fasculas</li> </ul>"},{"location":"#5-exportacao-e-carga","title":"5. Exporta\u00e7\u00e3o e Carga","text":"<ul> <li>CSV Paralelo: exporta\u00e7\u00e3o usando joblib com configura\u00e7\u00e3o de jobs</li> <li>Carga Postgres: via COPY com pol\u00edticas por tipo de atualiza\u00e7\u00e3o</li> <li><code>DELETE</code>: para atualiza\u00e7\u00f5es incremental/di\u00e1ria</li> <li><code>TRUNCATE</code>: para atualiza\u00e7\u00f5es full</li> </ul>"},{"location":"#fluxo-de-processamento","title":"Fluxo de Processamento","text":"Diagrama de Fluxo ETL Completo <p>O diagrama abaixo ilustra o fluxo completo de processamento dos pipelines ETL:</p> <pre><code>flowchart TD\n    A[MongoDB Collections] --&gt; B[gerar_base_para_busca]\n    B --&gt; C{Tipo de Atualiza\u00e7\u00e3o}\n\n    C --&gt;|DINAMICO| D[Calcular % Modifica\u00e7\u00f5es]\n    C --&gt;|DIARIO| E[Filtrar por Data Espec\u00edfica]\n    C --&gt;|INCREMENTAL| F[\u00daltimos N Dias]\n    C --&gt;|FULL| G[Todos os Bilhetes]\n\n    D --&gt; H{% &gt; Limite?}\n    H --&gt;|Sim| G\n    H --&gt;|N\u00e3o| F\n\n    E --&gt; I[gerar_querys MongoDB]\n    F --&gt; I\n    G --&gt; I\n\n    I --&gt; J[buscar_infos_bilhetes]\n    I --&gt; K[buscar_parcelas]\n\n    J --&gt; L[DataFrame Infos]\n    K --&gt; M[DataFrame Parcelas]\n\n    L --&gt; N[Merge/Jun\u00e7\u00e3o]\n    M --&gt; N\n\n    N --&gt; O[tratamentos_df]\n    O --&gt; P[Valida\u00e7\u00e3o Schema Pandera]\n    P --&gt; Q[Exportar CSV Paralelo]\n\n    Q --&gt; R{Tipo Delete}\n    R --&gt;|INCREMENTAL/DIARIO| S[DELETE Registros]\n    R --&gt;|FULL| T[TRUNCATE Tabela]\n\n    S --&gt; U[Importar via COPY]\n    T --&gt; U\n\n    U --&gt; V[Criar \u00cdndices]\n    V --&gt; W[Pipeline Conclu\u00eddo]\n\n    %% Estilos para modo claro e escuro\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#ffffff\n    style W fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#ffffff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#ffffff\n    style H fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#ffffff\n    style R fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#ffffff\n    style S fill:#F44336,stroke:#D32F2F,stroke-width:2px,color:#ffffff\n    style T fill:#F44336,stroke:#D32F2F,stroke-width:2px,color:#ffffff\n    style B fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#ffffff\n    style D fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#ffffff\n    style E fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#ffffff\n    style F fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#ffffff\n    style G fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#ffffff\n    style I fill:#795548,stroke:#5D4037,stroke-width:2px,color:#ffffff\n    style J fill:#00BCD4,stroke:#0097A7,stroke-width:2px,color:#ffffff\n    style K fill:#00BCD4,stroke:#0097A7,stroke-width:2px,color:#ffffff\n    style L fill:#FFC107,stroke:#FFA000,stroke-width:2px,color:#000000\n    style M fill:#FFC107,stroke:#FFA000,stroke-width:2px,color:#000000\n    style N fill:#E91E63,stroke:#C2185B,stroke-width:2px,color:#ffffff\n    style O fill:#3F51B5,stroke:#303F9F,stroke-width:2px,color:#ffffff\n    style P fill:#009688,stroke:#00796B,stroke-width:2px,color:#ffffff\n    style Q fill:#8BC34A,stroke:#689F38,stroke-width:2px,color:#000000\n    style U fill:#CDDC39,stroke:#AFB42B,stroke-width:2px,color:#000000\n    style V fill:#673AB7,stroke:#512DA8,stroke-width:2px,color:#ffffff</code></pre> <p>Legenda do Fluxo:</p> <ul> <li>\ud83d\udd35 Azul: Fonte de dados (MongoDB)</li> <li>\ud83d\udfe2 Verde: Conclus\u00e3o do pipeline</li> <li>\ud83d\udfe0 Laranja: Pontos de decis\u00e3o cr\u00edticos</li> <li>\ud83d\udd34 Vermelho: Opera\u00e7\u00f5es de limpeza (DELETE/TRUNCATE)</li> <li>\ud83d\udfe3 Roxo: Processamento inicial e \u00edndices</li> <li>\u26ab Cinza: Filtros e sele\u00e7\u00f5es de dados</li> <li>\ud83d\udfe4 Marrom: Gera\u00e7\u00e3o de queries MongoDB</li> <li>\ud83d\udd37 Ciano: Busca e coleta de dados</li> <li>\ud83d\udfe1 Amarelo: DataFrames intermedi\u00e1rios</li> <li>\ud83c\udf38 Rosa: Opera\u00e7\u00f5es de jun\u00e7\u00e3o/merge</li> <li>\ud83d\udfe6 Azul Escuro: Tratamentos e transforma\u00e7\u00f5es</li> <li>\ud83d\udfe2 Verde Escuro: Valida\u00e7\u00e3o de schema</li> <li>\ud83d\udfe2 Verde Claro: Exporta\u00e7\u00e3o CSV</li> <li>\ud83d\udfe8 Lima: Importa\u00e7\u00e3o para PostgreSQL</li> </ul> <p>Notas T\u00e9cnicas:</p> <ul> <li>Modo DIN\u00c2MICO: Avalia % de modifica\u00e7\u00f5es para decidir entre INCREMENTAL ou FULL</li> <li>Processamento Paralelo: Busca de bilhetes e parcelas executada simultaneamente</li> <li>Otimiza\u00e7\u00e3o de Performance: \u00cdndices removidos durante carga e recriados ap\u00f3s</li> <li>Valida\u00e7\u00e3o Rigorosa: Schema Pandera em modo strict antes da exporta\u00e7\u00e3o</li> </ul>"},{"location":"#estrutura-de-arquivos-por-produto","title":"Estrutura de Arquivos por Produto","text":"<p>Cada produto segue a mesma estrutura de arquivos:</p> <pre><code>produto/\n\u251c\u2500\u2500 main_produto.py                     # Orquestra\u00e7\u00e3o principal\n\u251c\u2500\u2500 pipeline_produto_funcoes.py         # L\u00f3gica de neg\u00f3cio e transforma\u00e7\u00f5es\n\u2514\u2500\u2500 pipeline_produto_notebook.ipynb     # Notebook para desenvolvimento e testes\n</code></pre>"},{"location":"#configuracoes-padrao","title":"Configura\u00e7\u00f5es Padr\u00e3o","text":""},{"location":"#variaveis-comuns-main_produtopy","title":"Vari\u00e1veis Comuns (<code>main_&lt;produto&gt;.py</code>):","text":"<pre><code>AMBIENTE_MONGO = 'PRODUCAO'                 # Ambiente MongoDB\nQDE_DIAS_RETROATIVOS = 3                    # Dias para busca incremental\nPERCENTUAL_MODIFICACAO_INCREMENTAL = 40     # Limite para modo DINAMICO\nTP_ATUALIZACAO = 'DINAMICO'                 # Tipo de atualiza\u00e7\u00e3o\nQDE_BILHETES = 5000                         # Lotes por query\nQDE_JOBS = 30                               # Paraleliza\u00e7\u00e3o\n</code></pre>"},{"location":"#constantes-padrao-pipeline_produto_funcoespy","title":"Constantes Padr\u00e3o (<code>pipeline_&lt;produto&gt;_funcoes.py</code>):","text":"<pre><code>ENCODING = 'utf-8'\nSEP = '|'\nEXTENSAO = 'csv'\nPATH = r\"E:\\ARQUIVOS_MONGO\\produto\"\nBANCO_UTILIZADO_PARA_IMPORTACAO = 'POSTGRES'\n</code></pre>"},{"location":"#calculo-padrao-de-valor-tarifario","title":"C\u00e1lculo Padr\u00e3o de Valor Tarif\u00e1rio","text":"<p>O c\u00e1lculo do <code>valor_tarifario</code> se repete para todos os produtos que possuem parcelas:</p> <pre><code># F\u00f3rmula padr\u00e3o aplicada na maioria dos produtos\nvalor_tarifario = round((valor_parcela / 107.38) * 100, 2)\n\n# Produtos com f\u00f3rmulas espec\u00edficas:\n# - Metlife Celular: divis\u00e3o por 1.0738\n# - Outros podem ter varia\u00e7\u00f5es conforme regras de neg\u00f3cio\n</code></pre> <p>Varia\u00e7\u00f5es por Produto</p> <p>Alguns produtos podem ter f\u00f3rmulas espec\u00edficas de c\u00e1lculo tarif\u00e1rio. Consulte a documenta\u00e7\u00e3o individual de cada produto para detalhes.</p>"},{"location":"#schema-e-validacao","title":"Schema e Valida\u00e7\u00e3o","text":""},{"location":"#campos-padrao-obrigatorios","title":"Campos Padr\u00e3o Obrigat\u00f3rios","text":"<p>Todos os produtos devem implementar os seguintes campos no schema Pandera:</p> Campo Tipo Obrigat\u00f3rio Descri\u00e7\u00e3o <code>uuid_bilhete</code> <code>str</code> Sim Identificador \u00fanico do bilhete <code>installmentsuuid</code> <code>str</code> Sim Identificador da parcela <code>valor_parcela</code> <code>float</code> Sim Valor da parcela <code>valor_tarifario</code> <code>float</code> Sim Valor tarif\u00e1rio calculado <code>transactionid</code> <code>str</code> Recomendado ID da transa\u00e7\u00e3o <code>data_inicio_vigencia</code> <code>pd.Timestamp</code> Sim Data in\u00edcio da vig\u00eancia <code>data_fim_vigencia</code> <code>pd.Timestamp</code> Sim Data fim da vig\u00eancia <code>data_vencimento</code> <code>pd.Timestamp</code> Sim Data vencimento da parcela <code>data_pagamento</code> <code>pd.Timestamp</code> Opcional Data do pagamento <code>data_cancelamento</code> <code>pd.Timestamp</code> Opcional Data do cancelamento <code>data_estorno</code> <code>pd.Timestamp</code> Opcional Data de estorno"},{"location":"#merge-e-juncao-de-dados","title":"Merge e Jun\u00e7\u00e3o de Dados","text":"<p>Campos t\u00edpicos usados como chaves de jun\u00e7\u00e3o entre collections:</p> Campo (Info) Campo (Parcela) Descri\u00e7\u00e3o <code>info_InstallmentsUUID</code> <code>InstallmentsUUID</code> UUID da parcela (principal chave de jun\u00e7\u00e3o) <code>uuid_bilhete</code> <code>uuid_bilhete</code> UUID do bilhete (identificador secund\u00e1rio) <p>Observa\u00e7\u00f5es sobre Merge</p> <ul> <li>As chaves exatas variam por produto - consulte documenta\u00e7\u00e3o espec\u00edfica</li> <li>Campos UUID s\u00e3o convertidos de Binary para string via <code>converter_bytes_para_uuid()</code></li> <li>Merge <code>outer</code> preserva registros \u00f3rf\u00e3os (infos sem parcelas e parcelas sem infos)</li> </ul>"},{"location":"#logs-e-monitoramento","title":"Logs e Monitoramento","text":""},{"location":"#logs-padrao","title":"Logs Padr\u00e3o","text":"<ul> <li>Quantidade de bilhetes processados</li> <li>Quantidade de arquivos gerados</li> <li>Progresso do processamento paralelo</li> <li>Tipo de atualiza\u00e7\u00e3o executada</li> <li>Percentual de modifica\u00e7\u00f5es (modo DINAMICO)</li> </ul>"},{"location":"#boas-praticas","title":"Boas Pr\u00e1ticas","text":""},{"location":"#performance","title":"Performance","text":"<ul> <li>Use lotes configur\u00e1veis (<code>QDE_BILHETES</code>)</li> <li>Configure paraleliza\u00e7\u00e3o adequada (<code>QDE_JOBS</code>)</li> <li>Monitore uso de mem\u00f3ria em volumes grandes</li> </ul> <p>Dica de Performance</p> <p>Para volumes grandes de dados, considere ajustar <code>QDE_BILHETES</code> e <code>QDE_JOBS</code> de acordo com os recursos dispon\u00edveis.</p> <p>Ferramentas do Projeto</p> <p>Para informa\u00e7\u00f5es detalhadas sobre os m\u00f3dulos utilit\u00e1rios (<code>tools/</code>) utilizados em todos os pipelines, consulte a se\u00e7\u00e3o Ferramentas.</p>"},{"location":"ferramentas/","title":"Ferramentas do Projeto","text":"<p>O diret\u00f3rio <code>tools/</code> cont\u00e9m m\u00f3dulos utilit\u00e1rios reutiliz\u00e1veis que padronizam opera\u00e7\u00f5es comuns entre todos os pipelines. Essas ferramentas abstraem complexidades de conectividade, transforma\u00e7\u00f5es de dados e opera\u00e7\u00f5es de banco, garantindo consist\u00eancia e manutenibilidade. </p>"},{"location":"ferramentas/#1-conexao-mongodb-conexao_mongopy","title":"1. Conex\u00e3o MongoDB (<code>conexao_mongo.py</code>)","text":"<p>Gerencia conex\u00f5es com clusters MongoDB de produ\u00e7\u00e3o e homologa\u00e7\u00e3o com autentica\u00e7\u00e3o segura.</p>"},{"location":"ferramentas/#abrir_conexao_mongoambiente","title":"<code>abrir_conexao_mongo(ambiente)</code>","text":"<p>Estabelece conex\u00e3o com o cluster MongoDB baseado no ambiente especificado.</p> <p>Funcionalidades:</p> <ul> <li> <p>Ambientes separados: Produ\u00e7\u00e3o e Homologa\u00e7\u00e3o com credenciais distintas</p> </li> <li> <p>Autentica\u00e7\u00e3o segura: Carregamento de credenciais via <code>.env</code></p> </li> <li> <p>Clusters espec\u00edficos: URIs otimizadas para cada ambiente</p> </li> <li> <p>Configura\u00e7\u00f5es otimizadas: TLS para produ\u00e7\u00e3o, prefer\u00eancia anal\u00edtica para homologa\u00e7\u00e3o</p> </li> </ul> Source code in tools/conexao_mongo.py <pre><code>def abrir_conexao_mongo(ambiente:Literal['PRODUCAO','HOMOLOGACAO']) -&gt; MongoClient:\n\"\"\"\nEstabelece conex\u00e3o com o cluster MongoDB baseado no ambiente especificado.\n\nEsta fun\u00e7\u00e3o gerencia conex\u00f5es seguras com clusters MongoDB de produ\u00e7\u00e3o e \nhomologa\u00e7\u00e3o, utilizando credenciais carregadas de vari\u00e1veis de ambiente\ne configura\u00e7\u00f5es otimizadas para cada ambiente.\n\nArgs:\n    ambiente (Literal['PRODUCAO','HOMOLOGACAO']): Ambiente de destino para \n        a conex\u00e3o. 'PRODUCAO' conecta ao cluster principal, 'HOMOLOGACAO' \n        conecta ao cluster de testes com prefer\u00eancia de leitura anal\u00edtica.\n\nReturns:\n    tuple[Database, MongoClient]: Tupla contendo:\n        - db: Objeto Database do MongoDB configurado para o ambiente\n        - client: Objeto MongoClient para gerenciamento da conex\u00e3o\n\nRaises:\n    Exception: Se o ambiente especificado n\u00e3o for 'PRODUCAO' ou 'HOMOLOGACAO'\n    Exception: Se houver falha na conex\u00e3o com o MongoDB\n\nExamples:\n    &gt;&gt;&gt; db, client = abrir_conexao_mongo('PRODUCAO')\n    &gt;&gt;&gt; # Usar db para opera\u00e7\u00f5es\n    &gt;&gt;&gt; client.close()  # Fechar conex\u00e3o quando terminar\n\n    &gt;&gt;&gt; db, client = abrir_conexao_mongo('HOMOLOGACAO')\n    &gt;&gt;&gt; collection = db.implementations.acidentepessoal\n    &gt;&gt;&gt; client.close()\n\nNote:\n    - Produ\u00e7\u00e3o: Conecta ao cluster skyedb-prod com TLS ativado\n    - Homologa\u00e7\u00e3o: Conecta ao cluster atlas-sql com prefer\u00eancia anal\u00edtica\n    - Credenciais devem estar configuradas no arquivo .env\n    - Sempre feche a conex\u00e3o ap\u00f3s o uso para evitar vazamentos\n\"\"\"\n\nambiente = ambiente.upper()\nif ambiente == 'PRODUCAO':\n    try:\n        uri = f\"mongodb+srv://{USUARIO_PROD}:{SENHA_PROD}@skyedb-prod.qy5pd6.mongodb.net/kovrprod1a?tls=true&amp;authSource=admin\"\n        client = MongoClient(uri)\n        db = client['kovrprod1a']\n    except Exception as e:\n        print(e)\n        if client:\n            client.close()\n\n\nelif ambiente == 'HOMOLOGACAO':\n    try:\n        uri = f\"mongodb+srv://{USUARIO_HOMOLOG}:{SENHA_HOMOLOG}@atlas-sql-6734bb7531b70b661025148c-6jkwl.a.query.mongodb.net/kovruat1a?ssl=true&amp;authSource=admin&amp;readPreference=secondary&amp;readPreferenceTags=nodeType:ANALYTICS\"\n        client = MongoClient(uri)\n        db = client['kovruat1a']\n    except Exception as e:\n        print(e)\n        if client:\n            client.close()\nelse:\n    raise Exception('Selecione um dos ambientes : PRODUCAO ou HOMOLOGACAO')\n\n\nreturn db,client\n</code></pre>"},{"location":"ferramentas/#2-conexao-postgresql-conexao_postgrespy","title":"2. Conex\u00e3o PostgreSQL (<code>conexao_postgres.py</code>)","text":"<p>M\u00f3dulo completo para opera\u00e7\u00f5es PostgreSQL incluindo importa\u00e7\u00e3o otimizada, gerenciamento de \u00edndices e estrat\u00e9gias de atualiza\u00e7\u00e3o.</p>"},{"location":"ferramentas/#funcoes-principais","title":"Fun\u00e7\u00f5es Principais:","text":""},{"location":"ferramentas/#abrir_conexao_postgresambiente","title":"<code>abrir_conexao_postgres(ambiente)</code>","text":"<p>Estabelece conex\u00e3o com o banco PostgreSQL baseado no ambiente especificado.</p> Source code in tools/conexao_postgres.py <pre><code>def abrir_conexao_postgres(ambiente:Literal['PRODUCAO','HOMOLOGACAO']) -&gt; psycopg2:\n\"\"\"\nEstabelece conex\u00e3o com o banco PostgreSQL baseado no ambiente especificado.\n\nEsta fun\u00e7\u00e3o cria uma conex\u00e3o segura com o PostgreSQL utilizando credenciais\nespec\u00edficas do ambiente (produ\u00e7\u00e3o ou homologa\u00e7\u00e3o) carregadas de vari\u00e1veis\nde ambiente configuradas no arquivo .env.\n\nArgs:\n    ambiente (Literal['PRODUCAO','HOMOLOGACAO']): Ambiente de destino para\n        a conex\u00e3o. Define qual conjunto de credenciais ser\u00e1 utilizado.\n\nReturns:\n    psycopg2.connection: Objeto de conex\u00e3o PostgreSQL configurado e ativo.\n\nRaises:\n    Exception: Se o ambiente especificado n\u00e3o for 'PRODUCAO' ou 'HOMOLOGACAO'\n    ValueError: Se houver falha na conex\u00e3o (credenciais inv\u00e1lidas, host inacess\u00edvel, etc.)\n\nExamples:\n    &gt;&gt;&gt; conn = abrir_conexao_postgres('PRODUCAO')\n    &gt;&gt;&gt; cur = conn.cursor()\n    &gt;&gt;&gt; cur.execute(\"SELECT 1\")\n    &gt;&gt;&gt; conn.close()\n\n    &gt;&gt;&gt; conn = abrir_conexao_postgres('HOMOLOGACAO')\n    &gt;&gt;&gt; # Usar conex\u00e3o para opera\u00e7\u00f5es de teste\n    &gt;&gt;&gt; conn.close()\n\nNote:\n    - Vari\u00e1veis de ambiente necess\u00e1rias:\n      - PRODUCAO: PG_HOST, PG_PORT, PG_DB, PG_USER, PG_PASSWORD\n      - HOMOLOGACAO: PG_HOMOLOG_HOST, PG_HOMOLOG_PORT, etc.\n    - Sempre feche a conex\u00e3o ap\u00f3s o uso\n    - A conex\u00e3o \u00e9 estabelecida via string de conex\u00e3o PostgreSQL padr\u00e3o\n\"\"\"\n\nif ambiente == 'PRODUCAO':\n    host = os.getenv(\"PG_HOST\")\n    port = os.getenv(\"PG_PORT\")\n    db   = os.getenv(\"PG_DB\")\n    user = os.getenv(\"PG_USER\")\n    pwd  = os.getenv(\"PG_PASSWORD\")\nelif ambiente == 'HOMOLOGACAO':\n    host = os.getenv(\"PG_HOMOLOG_HOST\")\n    port = os.getenv(\"PG_HOMOLOG_PORT\")\n    db   = os.getenv(\"PG_HOMOLOG_DB\")\n    user = os.getenv(\"PG_HOMOLOG_USER\")\n    pwd  = os.getenv(\"PG_HOMOLOG_PASSWORD\")\nelse:\n    raise Exception('Selecione um dos ambientes : PRODUCAO ou HOMOLOGACAO')\n\nurl_format =  f\"postgresql://{user}:{pwd}@{host}:{port}/{db}\"\n\ntry:\n    con = psycopg2.connect(url_format)\nexcept Exception as e:\n    print(f'###########  Erro ao efetuar a conex\u00e3o cnx_str: {url_format}')\n    raise ValueError(e)\nreturn con\n</code></pre>"},{"location":"ferramentas/#consultar_colunas_tabelaambiente-nm_tabela","title":"<code>consultar_colunas_tabela(ambiente, nm_tabela)</code>","text":"<p>Consulta e retorna a lista ordenada de colunas de uma tabela PostgreSQL.</p>"},{"location":"ferramentas/#tipo_delete_postgrestp_atualizacao","title":"<code>tipo_delete_postgres(tp_atualizacao)</code>","text":"<p>Determina o tipo de opera\u00e7\u00e3o de remo\u00e7\u00e3o baseado no tipo de atualiza\u00e7\u00e3o.</p> <ul> <li>DELETE: Para atualiza\u00e7\u00f5es incrementais/di\u00e1rias (remove apenas registros espec\u00edficos)</li> <li>TRUNCATE: Para atualiza\u00e7\u00f5es completas (limpa toda a tabela)</li> </ul>"},{"location":"ferramentas/#remover_registrosambiente-nm_tabela-tp_delete-registros","title":"<code>remover_registros(ambiente, nm_tabela, tp_delete, registros)</code>","text":"<p>Remove registros de uma tabela PostgreSQL usando DELETE ou TRUNCATE.</p> <p>Caracter\u00edsticas:</p> <ul> <li> <p>Processamento em lotes de 2000 UUIDs para otimiza\u00e7\u00e3o</p> </li> <li> <p>Commit autom\u00e1tico ap\u00f3s todas as opera\u00e7\u00f5es</p> </li> <li> <p>Remove valores nulos automaticamente</p> </li> </ul>"},{"location":"ferramentas/#importar_csv_copy_alinhadoambiente-caminho_csv-nome_tabela-colunas_tabela","title":"<code>importar_csv_copy_alinhado(ambiente, caminho_csv, nome_tabela, colunas_tabela)</code>","text":"<p>Importa\u00e7\u00e3o Otimizada com COPY Utiliza o comando nativo <code>COPY</code> do PostgreSQL para importa\u00e7\u00e3o de grandes volumes:</p> Source code in tools/conexao_postgres.py <pre><code>def importar_csv_copy_alinhado(ambiente: str, caminho_csv: str, nome_tabela: str, colunas_tabela: list, separador='|'):\n\"\"\"\nImporta dados CSV para PostgreSQL usando o comando nativo COPY.\n\nEsta fun\u00e7\u00e3o utiliza o comando COPY do PostgreSQL para importa\u00e7\u00e3o otimizada\nde grandes volumes de dados, oferecendo performance superior ao INSERT\ntradicional.\n\nArgs:\n    ambiente (str): Ambiente do banco ('PRODUCAO' ou 'HOMOLOGACAO')\n    caminho_csv (str): Caminho absoluto para o arquivo CSV\n    nome_tabela (str): Nome da tabela de destino\n    colunas_tabela (list[str]): Lista ordenada das colunas da tabela\n    separador (str, optional): Separador de campos do CSV. Defaults to '|'.\n\nRaises:\n    ValueError: Se houver erro no processamento do arquivo CSV\n\nExamples:\n    &gt;&gt;&gt; colunas = ['uuid_bilhete', 'valor_parcela', 'data_criacao']\n    &gt;&gt;&gt; importar_csv_copy_alinhado(\n    ...     'PRODUCAO', \n    ...     '/path/to/data.csv', \n    ...     'innoveo_kovr_ap', \n    ...     colunas\n    ... )\n\nNote:\n    - Utiliza COPY com FORMAT CSV para m\u00e1xima compatibilidade\n    - Configurado para tratar NULL como string vazia\n    - HEADER TRUE assume primeira linha como cabe\u00e7alho\n    - Escape de caracteres especiais configurado automaticamente\n\"\"\"\nconn = abrir_conexao_postgres(ambiente=ambiente)\ncur = conn.cursor()\ntry:\n    comando = sql.SQL(\"\"\"\n    COPY {tabela} ({colunas})\n    FROM {arquivo}\n    WITH (\n        FORMAT CSV,\n        DELIMITER {separador_coluna},\n        NULL '',\n        HEADER TRUE,\n        QUOTE '\"',\n        ESCAPE '\\\\'\n    )\n    \"\"\").format(\n        tabela=sql.Identifier(nome_tabela),\n        colunas=sql.SQL(', ').join(map(sql.Identifier, colunas_tabela)),\n        separador_coluna=sql.Literal(separador),\n        arquivo=sql.Literal(caminho_csv)\n    )\n\n    cur.execute(comando)\n    conn.commit()\n    cur.close()\n    conn.close()\nexcept Exception as e:\n    if cur:\n        cur.close()\n    if conn:\n        conn.close()\n    print(caminho_csv)\n\n    raise ValueError(f'Erro no processamento do arquivo: {caminho_csv} Erro: {e}')\n</code></pre>"},{"location":"ferramentas/#atualizar_tabela_postgres_arquivoambiente-arq-tp_atualizacao-nm_tabela","title":"<code>atualizar_tabela_postgres_arquivo(ambiente, arq, tp_atualizacao, nm_tabela)</code>","text":"<p>Atualiza tabela PostgreSQL com dados de arquivo CSV usando estrat\u00e9gia otimizada.</p> <p>Processo completo:</p> <ol> <li> <p>Determina tipo de opera\u00e7\u00e3o (DELETE/TRUNCATE)</p> </li> <li> <p>Remove registros existentes conforme necess\u00e1rio</p> </li> <li> <p>Importa novos dados usando COPY nativo</p> </li> </ol>"},{"location":"ferramentas/#remover_indices_postgresambiente-nm_tabela-e-criar_indicesambiente-indexes-nm_tabela","title":"<code>remover_indices_postgres(ambiente, nm_tabela)</code> e <code>criar_indices(ambiente, indexes, nm_tabela)</code>","text":"<p>Gerenciamento Din\u00e2mico de \u00cdndices Remove \u00edndices antes de cargas grandes e os recria ap\u00f3s:</p> Source code in tools/conexao_postgres.py <pre><code>def remover_indices_postgres(ambiente: Literal['PRODUCAO','HOMOLOGACAO'], nm_tabela: str):\n\"\"\"\nRemove todos os \u00edndices de uma tabela, preservando constraints (PK/FK/UNIQUE).\n\nEsta fun\u00e7\u00e3o otimiza cargas de dados removendo \u00edndices n\u00e3o-essenciais\nantes de opera\u00e7\u00f5es de importa\u00e7\u00e3o em massa, melhorando significativamente\na performance de inser\u00e7\u00e3o.\n\nArgs:\n    ambiente (Literal['PRODUCAO','HOMOLOGACAO']): Ambiente do banco\n    nm_tabela (str): Nome da tabela para remover \u00edndices\n\nExamples:\n    &gt;&gt;&gt; remover_indices_postgres('PRODUCAO', 'innoveo_kovr_ap')\n    # Remove \u00edndices como idx_kovr_ap_uuid_bilhete, mas preserva PKs\n\nNote:\n    - Preserva \u00edndices de PRIMARY KEY, FOREIGN KEY e UNIQUE constraints\n    - Remove apenas \u00edndices criados manualmente para otimiza\u00e7\u00e3o\n    - Opera\u00e7\u00e3o segura - n\u00e3o afeta integridade referencial\n    - Use antes de cargas grandes, recrie \u00edndices ap\u00f3s importa\u00e7\u00e3o\n    - Schema padr\u00e3o \u00e9 'public', ajuste se necess\u00e1rio\n\"\"\"\n\"\"\"\nRemove todos os \u00edndices de uma tabela, exceto \u00edndices de PK/FK/unique constraints.\n\"\"\"\nschema = 'public'  # ajuste se necess\u00e1rio\nconn = abrir_conexao_postgres(ambiente=ambiente)\n\ntry:\n    with conn.cursor() as cur:\n        # Buscar \u00edndices que n\u00e3o s\u00e3o constraints\n        cur.execute(\"\"\"\n            SELECT indexname\n            FROM pg_indexes\n            WHERE schemaname = %s\n                AND tablename = %s\n                AND indexname NOT IN (\n                    SELECT conname\n                    FROM pg_constraint\n                    WHERE conrelid = %s::regclass\n                )\n        \"\"\", (schema, nm_tabela, nm_tabela))\n\n        indexes = cur.fetchall()\n\n        for idx_name, in indexes:\n            print(f\"Dropping index {idx_name}...\")\n            cur.execute(sql.SQL(\"DROP INDEX IF EXISTS {}\").format(sql.Identifier(idx_name)))\n\n    conn.commit()\n    print(\"Todos os \u00edndices removidos (exceto constraints).\")\n\nfinally:\n    conn.close()\n</code></pre> Source code in tools/conexao_postgres.py <pre><code>def criar_indices(ambiente: Literal['PRODUCAO','HOMOLOGACAO'],indexes: dict, nm_tabela: str):\n\"\"\"\nCria \u00edndices n\u00e3o-\u00fanicos em uma tabela PostgreSQL de forma segura.\n\nEsta fun\u00e7\u00e3o cria \u00edndices de otimiza\u00e7\u00e3o para melhorar performance de queries,\nutilizando CREATE INDEX IF NOT EXISTS para evitar erros em execu\u00e7\u00f5es\nrepetidas.\n\nArgs:\n    ambiente (Literal['PRODUCAO','HOMOLOGACAO']): Ambiente do banco\n    indexes (dict): Dicion\u00e1rio {nome_indice: coluna_ou_lista_colunas}\n    nm_tabela (str): Nome da tabela onde criar os \u00edndices\n\nExamples:\n    &gt;&gt;&gt; indices = {\n    ...     'idx_kovr_ap_uuid_bilhete': 'uuid_bilhete',\n    ...     'idx_kovr_ap_data_criacao': 'data_criacao',\n    ...     'idx_kovr_ap_composto': ['uuid_bilhete', 'data_criacao']\n    ... }\n    &gt;&gt;&gt; criar_indices('PRODUCAO', indices, 'innoveo_kovr_ap')\n\nNote:\n    - Sempre cria \u00edndices n\u00e3o-\u00fanicos para evitar conflitos\n    - Suporta \u00edndices simples (uma coluna) e compostos (m\u00faltiplas colunas)\n    - IF NOT EXISTS evita erros se \u00edndice j\u00e1 existir\n    - Use ap\u00f3s cargas de dados para otimizar consultas\n    - Opera\u00e7\u00e3o com commit autom\u00e1tico\n\"\"\"\n\"\"\"\nCria \u00edndices n\u00e3o-\u00fanicos na tabela se n\u00e3o existirem.\n\n:param indexes: dicion\u00e1rio {nome_do_indice: coluna OU lista de colunas}\n\"\"\"\nconn = abrir_conexao_postgres(ambiente=ambiente)\nprint(f'{fc.data_hora()} Criando \u00edndices...')\ntry:\n    with conn.cursor() as cur:\n        for index_name, columns in indexes.items():\n            # Garante que columns seja lista\n            if isinstance(columns, str):\n                columns = [columns]\n\n            cols_sql = sql.SQL(\", \").join(map(sql.Identifier, columns))\n            # REMOVE dynamismo do UNIQUE, sempre non-unique\n            unique_clause = sql.SQL(\"\")  # sempre vazio\n\n            query = sql.SQL(\"CREATE {}INDEX IF NOT EXISTS {} ON {} ({})\").format(\n                unique_clause,\n                sql.Identifier(index_name),\n                sql.Identifier(nm_tabela),\n                cols_sql\n            )\n\n            cur.execute(query)\n            print(f\"\u00cdndice {index_name} criado na tabela {nm_tabela} (n\u00e3o-\u00fanico).\")\n\n    conn.commit()\n\nfinally:\n    print(f'{fc.data_hora()} Finalizando cria\u00e7\u00e3o de \u00edndices...')\n    conn.close()\n</code></pre>"},{"location":"ferramentas/#3-conexao-sql-server-conexao_sqlserverpy","title":"3. Conex\u00e3o SQL Server (<code>conexao_sqlserver.py</code>)","text":"<p>Alternativa ao PostgreSQL com suporte a:</p> <ul> <li> <p>BULK INSERT: Importa\u00e7\u00e3o nativa do SQL Server</p> </li> <li> <p>fast_executemany: Inser\u00e7\u00e3o otimizada com tratamento de tipos</p> </li> <li> <p>Alta performance: Processamento em lotes para grandes volumes</p> </li> </ul>"},{"location":"ferramentas/#funcoes-principais_1","title":"Fun\u00e7\u00f5es Principais:","text":""},{"location":"ferramentas/#abrir_conexao_sqlserverambiente","title":"<code>abrir_conexao_sqlserver(ambiente)</code>","text":"<p>Estabelece conex\u00e3o com SQL Server utilizando driver ODBC otimizado.</p>"},{"location":"ferramentas/#consultar_colunas_tabelaambiente-nm_tabela_1","title":"<code>consultar_colunas_tabela(ambiente, nm_tabela)</code>","text":"<p>Consulta schema usando INFORMATION_SCHEMA padr\u00e3o do SQL Server.</p>"},{"location":"ferramentas/#importar_csv_bulkambiente-caminho_csv-nome_tabela","title":"<code>importar_csv_bulk(ambiente, caminho_csv, nome_tabela)</code>","text":"<p>BULK INSERT Nativo Importa\u00e7\u00e3o otimizada usando comando nativo do SQL Server:</p> Source code in tools/conexao_sqlserver.py <pre><code>def importar_csv_bulk(ambiente:str, caminho_csv:str, nome_tabela:str, separador='|', first_row_header=True):\n\"\"\"\nImporta dados CSV para SQL Server usando BULK INSERT nativo.\n\nEsta fun\u00e7\u00e3o utiliza o comando BULK INSERT do SQL Server para importa\u00e7\u00e3o\notimizada de grandes volumes de dados, oferecendo performance superior\nao INSERT tradicional.\n\nArgs:\n    ambiente (str): Ambiente do banco ('PRODUCAO' ou 'HOMOLOGACAO')\n    caminho_csv (str): Caminho absoluto para o arquivo CSV\n    nome_tabela (str): Nome da tabela de destino\n    separador (str, optional): Separador de campos do CSV. Defaults to '|'.\n    first_row_header (bool, optional): Se primeira linha \u00e9 cabe\u00e7alho. Defaults to True.\n\nExamples:\n    &gt;&gt;&gt; importar_csv_bulk(\n    ...     'PRODUCAO', \n    ...     'C:\\\\dados\\\\arquivo.csv', \n    ...     'innoveo_kovr_ap'\n    ... )\n\nNote:\n    - Utiliza BULK INSERT com TABLOCK para m\u00e1xima performance\n    - FIELDTERMINATOR e ROWTERMINATOR configur\u00e1veis\n    - FIRSTROW = 2 quando first_row_header=True (pula cabe\u00e7alho)\n    - Caminho deve ser acess\u00edvel pelo servidor SQL Server\n    - Escapes de barras invertidas tratados automaticamente\n\"\"\"\n# Conex\u00e3o\ncon = abrir_conexao_sqlserver(ambiente)\ntry:\n    cur = con.cursor()\n    header_option = \"FIRSTROW = 2\" if first_row_header else \"FIRSTROW = 1\"\n    # Escapa corretamente as barras invertidas\n    caminho_csv_escaped = caminho_csv.replace(\"\\\\\", \"\\\\\\\\\")\n    comando_bulk = f\"\"\"\n        BULK INSERT {nome_tabela}\n        FROM '{caminho_csv_escaped}'\n        WITH (\n            FIELDTERMINATOR = '{separador}',\n            ROWTERMINATOR = '\\\\n',\n            {header_option},\n            TABLOCK\n        )\n    \"\"\"\n    cur.execute(comando_bulk)\n    con.commit()\nfinally:\n    con.close()\n</code></pre>"},{"location":"ferramentas/#importar_csv_fast_executemanyambiente-caminho_csv-nome_tabela-colunas_tabela-tipos_tabela","title":"<code>importar_csv_fast_executemany(ambiente, caminho_csv, nome_tabela, colunas_tabela, tipos_tabela)</code>","text":"<p>Fast ExecuteMany com Tratamento de Tipos Alternativa ao BULK INSERT com maior controle sobre tipos de dados:</p> <p>Caracter\u00edsticas:</p> <ul> <li> <p>fast_executemany habilitado para performance otimizada</p> </li> <li> <p>Tratamento autom\u00e1tico de tipos: FLOAT, DATE, DATETIME, VARCHAR</p> </li> <li> <p>Valores vazios convertidos para NULL</p> </li> <li> <p>Processamento em chunks (500k registros padr\u00e3o)</p> </li> <li> <p>Alinhamento autom\u00e1tico entre colunas CSV e tabela</p> </li> </ul>"},{"location":"ferramentas/#atualizar_tabela_sqlserver_arquivoambiente-arq-tp_atualizacao-nm_tabela-tipo_importacao","title":"<code>atualizar_tabela_sqlserver_arquivo(ambiente, arq, tp_atualizacao, nm_tabela, tipo_importacao)</code>","text":"<p>Coordena processo completo com op\u00e7\u00e3o de escolher entre BULK INSERT ou fast_executemany.</p>"},{"location":"ferramentas/#4-funcoes-gerais-funcoes_geraispy","title":"4. Fun\u00e7\u00f5es Gerais (<code>funcoes_gerais.py</code>)","text":"<p>Biblioteca de utilit\u00e1rios para transforma\u00e7\u00f5es de dados e opera\u00e7\u00f5es comuns.</p>"},{"location":"ferramentas/#principais-funcionalidades","title":"Principais Funcionalidades:","text":""},{"location":"ferramentas/#data_hora","title":"<code>data_hora()</code>","text":"<p>Retorna timestamp formatado para logs em portugu\u00eas brasileiro.</p> Source code in tools/funcoes_gerais.py <pre><code>def data_hora():\n    \"\"\"\n    Retorna a data e hora atual formatada para logs e exibi\u00e7\u00e3o.\n\n    Returns:\n        str: Data e hora no formato 'AAAA-MM-DD HHh MMm SSs'\n\n    Examples:\n        &gt;&gt;&gt; data_hora()\n        '2025-09-19 14h 30m 45s'\n    \"\"\"\n    return datetime.now().strftime('%Y-%m-%d %Hh %Mm %Ss')\n</code></pre>"},{"location":"ferramentas/#codificar_text_para_bytesvalue-e-converter_bytes_para_uuidvalor","title":"<code>codificar_text_para_bytes(value)</code> e <code>converter_bytes_para_uuid(valor)</code>","text":"<p>Convers\u00e3o de UUIDs MongoDB Converte entre formatos Binary (MongoDB) e string (PostgreSQL):</p> Source code in tools/funcoes_gerais.py <pre><code>def codificar_text_para_bytes(value):\n\"\"\"\nConverte UUID em v\u00e1rios formatos para Binary subtype 4 do MongoDB.\n\nEsta fun\u00e7\u00e3o \u00e9 essencial para intera\u00e7\u00e3o com MongoDB, convertendo UUIDs\nem formato bin\u00e1rio compat\u00edvel com as collections do banco. Aceita\nm\u00faltiplos formatos de entrada e trata valores vazios adequadamente.\n\nArgs:\n    value: UUID em formato uuid.UUID, bytes(16), string com/sem h\u00edfens,\n           ou valores vazios (None, '')\n\nReturns:\n    bson.Binary or None: UUID em formato bin\u00e1rio MongoDB ou None para valores vazios\n\nRaises:\n    ValueError: Para valores inv\u00e1lidos de UUID (bytes com tamanho incorreto, \n               strings malformadas)\n    TypeError: Para tipos n\u00e3o suportados\n\nExamples:\n    &gt;&gt;&gt; import uuid\n    &gt;&gt;&gt; # String com h\u00edfens\n    &gt;&gt;&gt; codificar_text_para_bytes('550e8400-e29b-41d4-a716-446655440000')\n    Binary(b'U\\x0e\\x84\\x00\\xe2\\x9b...', 4)\n\n    &gt;&gt;&gt; # String sem h\u00edfens\n    &gt;&gt;&gt; codificar_text_para_bytes('550e8400e29b41d4a716446655440000')\n    Binary(b'U\\x0e\\x84\\x00\\xe2\\x9b...', 4)\n\n    &gt;&gt;&gt; # Objeto UUID\n    &gt;&gt;&gt; codificar_text_para_bytes(uuid.UUID('550e8400-e29b-41d4-a716-446655440000'))\n    Binary(b'U\\x0e\\x84\\x00\\xe2\\x9b...', 4)\n\n    &gt;&gt;&gt; # Valores vazios\n    &gt;&gt;&gt; codificar_text_para_bytes(None)\n    None\n    &gt;&gt;&gt; codificar_text_para_bytes('')\n    None\n\nNote:\n    - Utiliza UUID_SUBTYPE (4) padr\u00e3o do MongoDB\n    - Ignora valores vazios retornando None\n    - Suporta UUIDs com e sem h\u00edfens\n    - Essencial para queries MongoDB com UUIDs\n\"\"\"\n\"\"\"\nConverte UUID em v\u00e1rios formatos para Binary subtype 4 do Mongo.\nAceita: uuid.UUID, bytes(16), string com/sem h\u00edfens.\nIgnora valores vazios (None, '') retornando None.\n\"\"\"\n# Ignora valores vazios\nif value in (None, ''):\n    return None\n\nif isinstance(value, uuid.UUID):\n    return Binary(value.bytes, subtype=UUID_SUBTYPE)\n\nif isinstance(value, bytes):\n    if len(value) == 16:\n        return Binary(value, subtype=UUID_SUBTYPE)\n    else:\n        raise ValueError(f\"Bytes inv\u00e1lidos para UUID: {value}\")\n\nif isinstance(value, str):\n    clean_val = value.strip().lower()\n    if clean_val == '':\n        return None\n    try:\n        if '-' in clean_val:\n            return Binary(uuid.UUID(clean_val).bytes, subtype=UUID_SUBTYPE)\n        else:\n            return Binary(uuid.UUID(hex=clean_val).bytes, subtype=UUID_SUBTYPE)\n    except Exception as e:\n        raise ValueError(f\"String inv\u00e1lida para UUID: {value} ({e})\")\n\nraise TypeError(f\"Tipo n\u00e3o suportado para UUID: {type(value)}\")\n</code></pre> Source code in tools/funcoes_gerais.py <pre><code>def converter_bytes_para_uuid(valor):\n\"\"\"\nConverte UUID em formato bin\u00e1rio do MongoDB para string leg\u00edvel.\n\nEsta fun\u00e7\u00e3o \u00e9 fundamental para processar dados extra\u00eddos do MongoDB,\nconvertendo UUIDs bin\u00e1rios (Binary subtype 4) para formato string\npadr\u00e3o com h\u00edfens.\n\nArgs:\n    valor: UUID em formato bytes/bytearray (16 bytes) ou qualquer outro tipo\n\nReturns:\n    str: UUID no formato string com h\u00edfens ou valor original convertido para string\n\nExamples:\n    &gt;&gt;&gt; # Bytes de 16 posi\u00e7\u00f5es (UUID bin\u00e1rio)\n    &gt;&gt;&gt; bytes_uuid = b'U\\x0e\\x84\\x00\\xe2\\x9b...'\n    &gt;&gt;&gt; converter_bytes_para_uuid(bytes_uuid)\n    '550e8400-e29b-41d4-a716-446655440000'\n\n    &gt;&gt;&gt; # Valor que n\u00e3o \u00e9 UUID bin\u00e1rio\n    &gt;&gt;&gt; converter_bytes_para_uuid('texto_qualquer')\n    'texto_qualquer'\n\n    &gt;&gt;&gt; # Bytes inv\u00e1lidos (n\u00e3o \u00e9 UUID)\n    &gt;&gt;&gt; converter_bytes_para_uuid(b'abc')\n    \"b'abc'\"\n\nNote:\n    - Valida se bytes tem exatamente 16 posi\u00e7\u00f5es (UUID v\u00e1lido)\n    - Retorna None para UUIDs bin\u00e1rios inv\u00e1lidos\n    - Para valores n\u00e3o-UUID, converte para string\n    - Essencial para normalizar dados do MongoDB\n\"\"\"\n'''\ntransforma uma UUID em Bin\u00e1rio para Texto \nEx: %e-a^d45 para '12015-adv8s-5ftr89-125sfv-36adc\n'''\n\nif isinstance(valor, (bytes, bytearray)) and len(valor) == 16:\n    try:\n        return str(uuid.UUID(bytes=valor))\n    except ValueError:\n        return None\nreturn str(valor)  # retorna o valor original se n\u00e3o for bytes/UUID\n</code></pre>"},{"location":"ferramentas/#converter_coluna_para_numericodf-coluna","title":"<code>converter_coluna_para_numerico(df, coluna)</code>","text":"<p>Convers\u00e3o Inteligente de N\u00fameros Processa valores monet\u00e1rios com formata\u00e7\u00e3o brasileira:</p> Source code in tools/funcoes_gerais.py <pre><code>def converter_coluna_para_numerico(df, coluna):\n\"\"\"\nConverte coluna de texto com valores monet\u00e1rios brasileiros para num\u00e9ricos.\n\nEsta fun\u00e7\u00e3o trata formata\u00e7\u00e3o brasileira de n\u00fameros, removendo s\u00edmbolos\nmonet\u00e1rios, espa\u00e7os e convertendo v\u00edrgulas decimais para pontos.\nValores inv\u00e1lidos s\u00e3o convertidos para NaN automaticamente.\n\nArgs:\n    df (pd.DataFrame): DataFrame contendo a coluna a ser convertida\n    coluna (str): Nome da coluna para convers\u00e3o\n\nReturns:\n    pd.Series: S\u00e9rie convertida para valores num\u00e9ricos (float)\n\nExamples:\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; df = pd.DataFrame({\n    ...     'valores': ['R$ 1.234,56', '2.500,00', '1,50', 'N/A']\n    ... })\n    &gt;&gt;&gt; df['valores_num'] = converter_coluna_para_numerico(df, 'valores')\n    &gt;&gt;&gt; print(df['valores_num'])\n    0    1234.56\n    1    2500.00\n    2       1.50\n    3        NaN\n\n    &gt;&gt;&gt; # Valores com separa\u00e7\u00e3o de milhares\n    &gt;&gt;&gt; df2 = pd.DataFrame({\n    ...     'preco': ['R$ 15.000,99', '1.000.000,50']\n    ... })\n    &gt;&gt;&gt; converter_coluna_para_numerico(df2, 'preco')\n    0      15000.99\n    1    1000000.50\n\nNote:\n    - Remove R$, espa\u00e7os e caracteres n\u00e3o-num\u00e9ricos\n    - Converte v\u00edrgula decimal para ponto\n    - Preserva separa\u00e7\u00e3o de milhares com ponto\n    - Valores inv\u00e1lidos viram NaN (pd.to_numeric errors='coerce')\n    - Ideal para processar dados financeiros brasileiros\n\"\"\"\n\"\"\"\nConverte uma coluna de texto com v\u00edrgulas (e opcionalmente separadores de milhar)\npara valores num\u00e9ricos (float). Valores inv\u00e1lidos s\u00e3o convertidos para NaN.\n\nPar\u00e2metros:\n    df (pd.DataFrame): O DataFrame contendo a coluna.\n    coluna (str): O nome da coluna a ser convertida.\n\nRetorna:\n    pd.Series: A coluna convertida para num\u00e9rico.\n\"\"\"\nreturn (\n    df[coluna]\n    .astype(str)\n    .str.replace(r'[^\\d,.-]', '', regex=True)  # remove R$, espa\u00e7os, etc\n    #.str.replace('.', '', regex=False)         # remove separador de milhar\n    .str.replace(',', '.', regex=False)        # converte decimal v\u00edrgula para ponto\n    .pipe(pd.to_numeric, errors='coerce')      # converte para n\u00famero, inv\u00e1lidos viram NaN\n)\n</code></pre>"},{"location":"ferramentas/#formatar_datas_coluna_rapidodf-coluna-nova_coluna","title":"<code>formatar_datas_coluna_rapido(df, coluna, nova_coluna)</code>","text":"<p>Parsing Inteligente de Datas Detecta automaticamente m\u00faltiplos formatos de data:</p> Source code in tools/funcoes_gerais.py <pre><code>def formatar_datas_coluna_rapido(df, coluna, nova_coluna):\n\"\"\"\nDetecta e converte automaticamente m\u00faltiplos formatos de data para datetime.\n\nEsta fun\u00e7\u00e3o utiliza uma lista de formatos comuns para detectar e converter\ndatas automaticamente, testando cada formato at\u00e9 encontrar uma correspond\u00eancia\nv\u00e1lida. \u00c9 ideal para processar dados com formatos de data inconsistentes.\n\nArgs:\n    df (pd.DataFrame): DataFrame contendo a coluna de datas\n    coluna (str): Nome da coluna com datas em formato string\n    nova_coluna (str): Nome da nova coluna que receber\u00e1 as datas convertidas\n\nReturns:\n    pd.DataFrame: DataFrame original com nova coluna de datas convertidas\n\nExamples:\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; df = pd.DataFrame({\n    ...     'data_str': ['2025.02.01', '01/02/2025', '2025-02-01', '01-02-2025']\n    ... })\n    &gt;&gt;&gt; df = formatar_datas_coluna_rapido(df, 'data_str', 'data_convertida')\n    &gt;&gt;&gt; print(df['data_convertida'])\n    0   2025-02-01\n    1   2025-02-01\n    2   2025-02-01\n    3   2025-02-01\n\n    &gt;&gt;&gt; # Com timestamps\n    &gt;&gt;&gt; df2 = pd.DataFrame({\n    ...     'timestamp': ['2024.06.25 05:02:46']\n    ... })\n    &gt;&gt;&gt; formatar_datas_coluna_rapido(df2, 'timestamp', 'datetime')\n\nNote:\n    - Formatos suportados:\n      - AAAA.MM.DD \n      - AAAA-MM-DD\n      - DD/MM/AAAA\n      - MM/DD/AA\n      - DD-MM-AAAA\n      - AAAA/MM/DD\n      - DD.MM.AAAA\n      - AAAA.MM.DD HH:MM:SS\n    - Processamento otimizado: para na primeira correspond\u00eancia\n    - Valores inv\u00e1lidos permanecem como NaT (Not a Time)\n    - Performance otimizada para grandes volumes\n\"\"\"\nformatos = [\n    \"%Y.%m.%d\",       # 2025.02.01\n    \"%Y-%m-%d\",       # 2025-02-01\n    \"%d/%m/%Y\",       # 01/02/2025\n    \"%m/%d/%y\",       # 02/01/2025\n    \"%d-%m-%Y\",       # 01-02-2025\n    \"%Y/%m/%d\",       # 2025/02/01\n    \"%d.%m.%Y\",       # 01.02.2025\n    \"%Y.%m.%d %H:%M:%S\"        #2024.06.25 05:02:46\n]\n\nresultado = pd.Series(pd.NaT, index=df.index)\n\nfor fmt in formatos:\n    mask = resultado.isna()\n    if not mask.any():\n        break\n    resultado[mask] = pd.to_datetime(df.loc[mask, coluna], format=fmt, errors='coerce')\n\ndf[nova_coluna] = resultado\nreturn df\n</code></pre>"},{"location":"ferramentas/#verificar_schema_tabelacolunas_tabela-df","title":"<code>verificar_schema_tabela(colunas_tabela, df)</code>","text":"<p>Valida\u00e7\u00e3o e Normaliza\u00e7\u00e3o de Schema Garante compatibilidade entre DataFrame e tabela de destino:</p> Source code in tools/funcoes_gerais.py <pre><code>def resetar_pasta_stage(path):\n\"\"\"\nLimpa e recria o diret\u00f3rio STAGE para processamento de arquivos tempor\u00e1rios.\n\nEsta fun\u00e7\u00e3o garante que o diret\u00f3rio STAGE esteja limpo antes de iniciar\no processamento, removendo todos os arquivos existentes e recriando\na estrutura necess\u00e1ria.\n\nArgs:\n    path (str): Caminho base onde existe/ser\u00e1 criado o diret\u00f3rio STAGE\n\nExamples:\n    &gt;&gt;&gt; resetar_pasta_stage('E:\\\\ARQUIVOS_MONGO\\\\kovr_ap')\n    2025-09-19 14h 30m 45s Limpamos o Diret\u00f3rio E:\\ARQUIVOS_MONGO\\kovr_ap\\STAGE\n\n    &gt;&gt;&gt; # Estrutura criada:\n    &gt;&gt;&gt; # E:\\ARQUIVOS_MONGO\\kovr_ap\\STAGE\\ (vazio e pronto para uso)\n\nNote:\n    - Remove completamente o diret\u00f3rio STAGE se existir\n    - Recria o diret\u00f3rio vazio\n    - Ignore errors=True evita erros se diret\u00f3rio n\u00e3o existir\n    - Inclui pausa de 3 segundos para garantir conclus\u00e3o\n    - Exibe mensagem de log com timestamp\n\"\"\"\ncaminho_stage = os.path.join(path,'STAGE')\nshutil.rmtree(caminho_stage,ignore_errors=True)\nos.makedirs(caminho_stage,exist_ok=True)\n\nprint(f'{data_hora()} Limpamos o Diret\u00f3rio {caminho_stage}')\ntime.sleep(3)\n</code></pre>"},{"location":"ferramentas/#resetar_pasta_stagepath-e-mover_arquivos_diariospath_arquivos","title":"<code>resetar_pasta_stage(path)</code> e <code>mover_arquivos_diarios(path_arquivos)</code>","text":"<p>Gerenciamento de Arquivos Tempor\u00e1rios Opera\u00e7\u00f5es otimizadas para processamento em lotes:</p> Source code in tools/funcoes_gerais.py <pre><code>def resetar_pasta_stage(path):\n\"\"\"\nLimpa e recria o diret\u00f3rio STAGE para processamento de arquivos tempor\u00e1rios.\n\nEsta fun\u00e7\u00e3o garante que o diret\u00f3rio STAGE esteja limpo antes de iniciar\no processamento, removendo todos os arquivos existentes e recriando\na estrutura necess\u00e1ria.\n\nArgs:\n    path (str): Caminho base onde existe/ser\u00e1 criado o diret\u00f3rio STAGE\n\nExamples:\n    &gt;&gt;&gt; resetar_pasta_stage('E:\\\\ARQUIVOS_MONGO\\\\kovr_ap')\n    2025-09-19 14h 30m 45s Limpamos o Diret\u00f3rio E:\\ARQUIVOS_MONGO\\kovr_ap\\STAGE\n\n    &gt;&gt;&gt; # Estrutura criada:\n    &gt;&gt;&gt; # E:\\ARQUIVOS_MONGO\\kovr_ap\\STAGE\\ (vazio e pronto para uso)\n\nNote:\n    - Remove completamente o diret\u00f3rio STAGE se existir\n    - Recria o diret\u00f3rio vazio\n    - Ignore errors=True evita erros se diret\u00f3rio n\u00e3o existir\n    - Inclui pausa de 3 segundos para garantir conclus\u00e3o\n    - Exibe mensagem de log com timestamp\n\"\"\"\ncaminho_stage = os.path.join(path,'STAGE')\nshutil.rmtree(caminho_stage,ignore_errors=True)\nos.makedirs(caminho_stage,exist_ok=True)\n\nprint(f'{data_hora()} Limpamos o Diret\u00f3rio {caminho_stage}')\ntime.sleep(3)\n</code></pre> Source code in tools/funcoes_gerais.py <pre><code>def mover_arquivos_diarios(path_arquivos):\n\"\"\"\nMove arquivos CSV do diret\u00f3rio STAGE para o diret\u00f3rio principal ap\u00f3s processamento.\n\nEsta fun\u00e7\u00e3o realiza a limpeza da pasta principal e depois move todos\nos arquivos CSV processados da pasta STAGE para a pasta principal,\nfinalizando o ciclo de processamento.\n\nArgs:\n    path_arquivos (str): Caminho base contendo as pastas principal e STAGE\n\nExamples:\n    &gt;&gt;&gt; mover_arquivos_diarios('E:\\\\ARQUIVOS_MONGO\\\\kovr_ap')\n    2025-09-19 14h 30m 45s Limpando pasta principal\n    2025-09-19 14h 30m 46s Movendo 5 arquivos\n\n    # Antes:\n    # E:\\ARQUIVOS_MONGO\\kovr_ap\\STAGE\\2025-01-01.csv\n    # E:\\ARQUIVOS_MONGO\\kovr_ap\\STAGE\\2025-01-02.csv\n\n    # Depois:\n    # E:\\ARQUIVOS_MONGO\\kovr_ap\\2025-01-01.csv\n    # E:\\ARQUIVOS_MONGO\\kovr_ap\\2025-01-02.csv\n\nNote:\n    - ETAPA 1: Remove todos os .csv da pasta principal\n    - ETAPA 2: Move todos os .csv da STAGE para principal\n    - Arquivos s\u00e3o movidos (n\u00e3o copiados) - STAGE fica vazia\n    - Logs informativos com contagem de arquivos\n    - Opera\u00e7\u00e3o segura - verifica exist\u00eancia antes de remover\n\"\"\"\nlista_arquivos = glob(os.path.join(path_arquivos,'*.csv'))\nprint(f' {data_hora()} Limpando pasta principal')\nfor arq in lista_arquivos:\n    if os.path.exists(arq):\n        os.remove(arq)\n\n\npath_stage = os.path.join(path_arquivos,'STAGE')\nlista_arquivos_stage = glob(os.path.join(path_stage,'*.csv'))\n\nprint(f' {data_hora()} Movendo {len(lista_arquivos_stage)} arquivos')\nfor arq in lista_arquivos_stage:\n    shutil.move(arq,path_arquivos)\n</code></pre>"},{"location":"ferramentas/#beneficios-da-arquitetura-modular","title":"Benef\u00edcios da Arquitetura Modular","text":""},{"location":"ferramentas/#reutilizacao","title":"Reutiliza\u00e7\u00e3o","text":"<ul> <li>Todas as opera\u00e7\u00f5es de banco s\u00e3o padronizadas</li> <li>Transforma\u00e7\u00f5es comuns centralizadas</li> <li>Redu\u00e7\u00e3o de duplica\u00e7\u00e3o de c\u00f3digo</li> <li>Fun\u00e7\u00f5es documentadas com exemplos pr\u00e1ticos</li> </ul>"},{"location":"ferramentas/#manutenibilidade","title":"Manutenibilidade","text":"<ul> <li>Mudan\u00e7as de conectividade em local \u00fanico</li> <li>Debugging simplificado com logs estruturados</li> <li>Versionamento consistente</li> <li>Docstrings completas para todas as fun\u00e7\u00f5es</li> </ul>"},{"location":"ferramentas/#performance","title":"Performance","text":"<ul> <li>Opera\u00e7\u00f5es otimizadas por tipo de banco (COPY, BULK INSERT, fast_executemany)</li> <li>Gest\u00e3o inteligente de recursos e mem\u00f3ria</li> <li>Processamento paralelo nativo</li> <li>Estrat\u00e9gias de atualiza\u00e7\u00e3o inteligentes (DELETE vs TRUNCATE)</li> </ul>"},{"location":"ferramentas/#consistencia","title":"Consist\u00eancia","text":"<ul> <li>Valida\u00e7\u00f5es padronizadas via <code>verificar_schema_tabela()</code></li> <li>Tratamento de erros uniforme</li> <li>Logs estruturados com timestamps leg\u00edveis</li> <li>Convers\u00f5es de dados padronizadas (UUIDs, datas, n\u00fameros)</li> </ul>"},{"location":"ferramentas/#flexibilidade","title":"Flexibilidade","text":"<ul> <li>Suporte a m\u00faltiplos bancos (PostgreSQL e SQL Server)</li> <li>M\u00faltiplos formatos de data detectados automaticamente</li> <li>Estrat\u00e9gias de importa\u00e7\u00e3o configur\u00e1veis</li> <li>Ambientes separados (Produ\u00e7\u00e3o/Homologa\u00e7\u00e3o)</li> </ul> <p>Configura\u00e7\u00e3o de Ambiente</p> <p>Todas as ferramentas dependem do arquivo <code>.env</code> para credenciais. Use <code>.env.example</code> como template e configure adequadamente para seu ambiente. Cada fun\u00e7\u00e3o possui docstring completa com exemplos de uso e notas t\u00e9cnicas importantes.</p>"},{"location":"sobre/","title":"Sobre","text":""},{"location":"sobre/#pipelines-mongodb","title":"PIPELINES MONGODB","text":"<p>Este projeto foi desenvolvido pela Equipe de Dados Kovr para automatizar a extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carga (ETL) de dados de collections MongoDB para tabelas Postgres, evitando usar a API dos produtos, o que causava um grande impacto operacional.</p>"},{"location":"sobre/#objetivo","title":"Objetivo","text":"<p>Padronizar e automatizar o processo de migra\u00e7\u00e3o de dados entre MongoDB e Postgres, garantindo:</p> <ul> <li>Consist\u00eancia: Todos os produtos seguem o mesmo padr\u00e3o arquitetural</li> <li>Escalabilidade: Processamento paralelo e configur\u00e1vel</li> <li>Qualidade: Valida\u00e7\u00e3o rigorosa com schemas Pandera</li> <li>Flexibilidade: M\u00faltiplos modos de atualiza\u00e7\u00e3o (Di\u00e1rio, Incremental, Full, Din\u00e2mico)</li> </ul>"},{"location":"sobre/#equipe","title":"Equipe","text":"<p>Equipe de Dados Kovr</p>"},{"location":"sobre/#desenvolvedores-do-projeto","title":"Desenvolvedores do Projeto","text":"<ul> <li>Thiago Holanda Ramalho - Thiago.Ramalho@kovr.com.br</li> <li>Lucas Silva Pereira - lucas.silva@kev.tech</li> <li>Matheus Araujo Oliveira - Matheus.Oliveira@kovr.com.br</li> <li>Ricardo Campos Lima Dufloth - ricardo.dufloth@kovr.com.br</li> </ul>"},{"location":"sobre/#responsabilidades-da-equipe","title":"Responsabilidades da Equipe","text":"<ul> <li>Desenvolvimento e manuten\u00e7\u00e3o dos pipelines</li> <li>Documenta\u00e7\u00e3o t\u00e9cnica</li> <li>Suporte </li> </ul>"},{"location":"sobre/#licenca","title":"Licen\u00e7a","text":"<p>Este projeto \u00e9 de uso interno da Kovr Seguradora.</p>"},{"location":"produtos/disney_ap/","title":"Disney AP","text":""},{"location":"produtos/disney_ap/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Disney AP extrai dados de duas collections no MongoDB espec\u00edficas para seguros Disney, aplica transforma\u00e7\u00f5es especializadas (incluindo dados Disney espec\u00edficos, benefici\u00e1rios JSON e UUIDs diferenciados) e carrega em uma \u00fanica tabela Postgres. Utiliza arquivo de proje\u00e7\u00e3o externo e gerenciamento avan\u00e7ado de \u00edndices.</p>"},{"location":"produtos/disney_ap/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.disneyap</code> (implementa\u00e7\u00e3o) e <code>implementations.pppbaseparcelas</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_disney_ap</code></li> </ul>"},{"location":"produtos/disney_ap/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas Disney</p> <ul> <li>Projection externa: Produto que utiliza arquivo <code>projection.json</code> separado para definir campos de proje\u00e7\u00e3o</li> <li>Benefici\u00e1rios JSON: campo espec\u00edfico para dados de benefici\u00e1rios em formato JSON</li> </ul> <p>Especificidades do Seguro Disney</p> <ul> <li>Projection file: arquivo JSON externo para controle de campos (n\u00e3o hardcoded no c\u00f3digo)</li> <li>Gerenciamento \u00edndices: cria\u00e7\u00e3o e remo\u00e7\u00e3o autom\u00e1tica de \u00edndices durante processamento</li> <li>Benefici\u00e1rios estruturados: dados JSON para m\u00faltiplos benefici\u00e1rios</li> </ul>"},{"location":"produtos/disney_ap/#funcionalidades-especiais","title":"Funcionalidades Especiais","text":""},{"location":"produtos/disney_ap/#projection-externa","title":"Projection Externa","text":"<p>Produto com arquivo JSON de proje\u00e7\u00e3o - controle externo de campos:</p> Source code in pipeline_disney_ap_funcoes.py <pre><code>def carregar_projection():\n    pasta_atual = Path(__file__).parent\n    caminho_arquivo = pasta_atual / \"projection.json\"\n\n    with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n        campos = json.load(f)   # lista de campos\n    projection = {campo: 1 for campo in campos}\n    return projection\n\n# Uso na gera\u00e7\u00e3o de queries\nprojection = carregar_projection()\n\n# Merge diferenciado com ProdutoUUID\ndf_parcelas = df_parcelas[df_parcelas['uuid_parcela'].isin(df_implementacao['uuid_parcela'].unique())]\ndf_fim_parcelas['uuid_bilhete'] = df_fim_parcelas['ProdutoUUID']\n</code></pre>"},{"location":"produtos/disney_ap/#gerenciamento-avancado-de-indices","title":"Gerenciamento Avan\u00e7ado de \u00cdndices","text":"<p>Sistema automatizado de cria\u00e7\u00e3o/remo\u00e7\u00e3o de \u00edndices:</p> Source code in pipeline_disney_ap_funcoes.py <pre><code># Remo\u00e7\u00e3o de \u00edndices antes do truncate\nif pg.tipo_delete_postgres(tp_att) == 'TRUNCATE':\n    pg.remover_indices_postgres(AMBIENTE_MONGO, nm_tabela=pipe_functions.NM_TABELA_BANCO)\n\n# Cria\u00e7\u00e3o de \u00edndices ap\u00f3s importa\u00e7\u00e3o\nif pg.tipo_delete_postgres(tp_att) == 'TRUNCATE':\n    pg.criar_indices(AMBIENTE_MONGO, nm_tabela=pipe_functions.NM_TABELA_BANCO, \n                    indexes=pipe_functions.INDEX_TABELA_BANCO)\n\n# \u00cdndices espec\u00edficos definidos\nINDEX_TABELA_BANCO = {\n    f'idx_{NM_TABELA_BANCO}_uuid_bilhete': 'uuid_bilhete',\n    f'idx_{NM_TABELA_BANCO}_bilhete': 'info_numeroproposta',\n    f'idx_{NM_TABELA_BANCO}_data_pagamento': 'data_pagamento',\n    f'idx_{NM_TABELA_BANCO}_data_vencimento': 'data_vencimento'\n}\n</code></pre>"},{"location":"produtos/disney_ap/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/disney_ap/#dados-essenciais","title":"Dados Essenciais","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaDisneyAP</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 UUID da parcela <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>numero</code> Sim \u2705 N\u00famero da parcela <code>status</code> Recomendado \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio (f\u00f3rmula padr\u00e3o) <code>info_iniciovigencia</code> Sim \u2705 In\u00edcio da vig\u00eancia do seguro Disney <code>info_fimvigencia</code> Sim \u2705 Fim da vig\u00eancia <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim \u2705 Data de estorno do bilhete <p>Projection Externa</p> <p>O Disney AP utiliza arquivo <code>projection.json</code> externo para definir campos de proje\u00e7\u00e3o MongoDB, permitindo controle flex\u00edvel sem altera\u00e7\u00e3o de c\u00f3digo.</p>"},{"location":"produtos/kovr_ap/","title":"Kovr AP","text":""},{"location":"produtos/kovr_ap/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Kovr AP extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega no Postgres. Suporta atualiza\u00e7\u00f5es incremental (baseado em modifica\u00e7\u00f5es recentes) ou full.</p>"},{"location":"produtos/kovr_ap/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.acidentepessoal</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentsconsumergeneric</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_kovr_ap</code></li> </ul>"},{"location":"produtos/kovr_ap/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura em duas collections: informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.acidentepessoal</code> e parcelas em <code>implementations.installmentsconsumergeneric</code> \u2014 buscadas separadamente e depois combinadas</li> <li>Parcela por linha: as parcelas s\u00e3o \"explodidas\" (one row per installment) em <code>buscar_parcelas</code> antes do merge; o DataFrame final mant\u00e9m uma linha por parcela (n\u00e3o agrupa parcelas por bilhete)</li> <li>Merge: a jun\u00e7\u00e3o entre infos e parcelas \u00e9 feita em <code>buscar_dados_bilhetes</code> usando <code>left_on='info_InstallmentsUUID'</code> e <code>right_on='InstallmentsUUID'</code> com <code>how='outer'</code> por padr\u00e3o \u2014 preserva registros de ambos os lados (infos sem parcelas e parcelas sem infos)</li> </ul>"},{"location":"produtos/kovr_ap/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaKovrAP</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> / <code>info_installmentsuuid</code> Sim \u2705 <code>installmentsuuid</code> vem da collection de parcelas; <code>info_installmentsuuid</code> pode vir do documento de info <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u2705 N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u274c Data de estorno do bilhete/ap\u00f3lice n\u00e3o esta presente no MongoDB Outros campos de comiss\u00e3o (ex.: <code>info_infokovr_commissionsisou</code>) Recomendado \u2705 <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaKovrAP</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p>"},{"location":"produtos/kovr_phone/","title":"Kovr Phone","text":""},{"location":"produtos/kovr_phone/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Kovr Phone extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega no Postgres. Suporta atualiza\u00e7\u00f5es incremental (baseado em modifica\u00e7\u00f5es recentes) ou full.</p>"},{"location":"produtos/kovr_phone/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.phoneprotection</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentsconsumergeneric</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_kovr_phone</code></li> </ul>"},{"location":"produtos/kovr_phone/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura em duas collections: informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.phoneprotection</code> e parcelas em <code>implementations.installmentsconsumergeneric</code> \u2014 buscadas separadamente e depois combinadas</li> <li>Parcela por linha: as parcelas s\u00e3o \"explodidas\" (one row per installment) em <code>buscar_parcelas</code> antes do merge; o DataFrame final mant\u00e9m uma linha por parcela (n\u00e3o agrupa parcelas por bilhete)</li> <li>Merge: a jun\u00e7\u00e3o entre infos e parcelas \u00e9 feita em <code>buscar_dados_bilhetes</code> usando <code>left_on='info_installmentsUUID'</code> e <code>right_on='installmentsUUID'</code> com <code>how='outer'</code> por padr\u00e3o \u2014 preserva registros de ambos os lados (infos sem parcelas e parcelas sem infos) </li> </ul>"},{"location":"produtos/kovr_phone/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaKovrPhone</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> / <code>info_installmentsuuid</code> Sim \u2705 <code>installmentsuuid</code> vem da collection de parcelas; <code>info_installmentsuuid</code> pode vir do documento de info <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u2705 N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u274c Data de estorno do bilhete/ap\u00f3lice n\u00e3o esta presente no MongoDB <code>info_phoneinfo_devicevalue</code> Espec\u00edfico Phone \u2705 Valor do dispositivo m\u00f3vel <code>info_phoneinfo_imei</code> Espec\u00edfico Phone \u2705 IMEI do aparelho <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaKovrPhone</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p>"},{"location":"produtos/kovr_vida/","title":"Kovr Vida","text":""},{"location":"produtos/kovr_vida/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Kovr Vida extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega no Postgres. Suporta atualiza\u00e7\u00f5es incremental (baseado em modifica\u00e7\u00f5es recentes) ou full.</p>"},{"location":"produtos/kovr_vida/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.vidakovr</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentsconsumergeneric</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_kovr_vida</code></li> </ul>"},{"location":"produtos/kovr_vida/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura em duas collections: informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.vidakovr</code> e parcelas em <code>implementations.installmentsconsumergeneric</code> \u2014 buscadas separadamente e depois combinadas</li> <li>Parcela por linha: as parcelas s\u00e3o \"explodidas\" (one row per installment) em <code>buscar_parcelas</code> antes do merge; o DataFrame final mant\u00e9m uma linha por parcela (n\u00e3o agrupa parcelas por bilhete)</li> <li>Merge: a jun\u00e7\u00e3o entre infos e parcelas \u00e9 feita em <code>buscar_dados_bilhetes</code> usando <code>left_on='info_installmentsUUID'</code> e <code>right_on='installmentsUUID'</code> com <code>how='outer'</code> por padr\u00e3o \u2014 preserva registros de ambos os lados (infos sem parcelas e parcelas sem infos)</li> <li>Coberturas: possui sistema completo de coberturas de seguro de vida com 10 tipos diferentes, cada um com 3 valores (Is, NET, Tarif)</li> </ul>"},{"location":"produtos/kovr_vida/#campos-principais","title":"Campos Principais","text":""},{"location":"produtos/kovr_vida/#coberturas-de-seguro-de-vida","title":"Coberturas de Seguro de Vida","text":"<p>O produto Vida possui um sistema robusto de coberturas, cada uma com tr\u00eas tipos de valores:</p> <p>Tipos de Valores</p> <ul> <li>Is: Valor segurado/import\u00e2ncia segurada</li> <li>NET: Valor l\u00edquido </li> <li>Tarif: Valor tarif\u00e1rio da cobertura</li> </ul>"},{"location":"produtos/kovr_vida/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaKovrVida</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> / <code>info_installmentsuuid</code> Sim \u2705 <code>installmentsuuid</code> vem da collection de parcelas; <code>info_installmentsuuid</code> pode vir do documento de info <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Opcional \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Opcional (usada como refer\u00eancia de estorno) \u274c Data de estorno do bilhete/ap\u00f3lice n\u00e3o esta presente no MongoDB <code>info_customerinfo_beneficiariosinfo</code> Espec\u00edfico Vida \u2705 Informa\u00e7\u00f5es dos benefici\u00e1rios Coberturas <code>info_customerinfo_coberturas_*</code> Espec\u00edfico Vida \u2705 <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaKovrVida</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p> <p>Especificidades do Vida</p> <ul> <li>Coberturas: 10 tipos de coberturas com 3 valores cada</li> <li>Dados atuariais: idade e status fumante s\u00e3o cr\u00edticos para c\u00e1lculo de risco</li> <li>Benefici\u00e1rios: informa\u00e7\u00f5es obrigat\u00f3rias para seguros de vida</li> </ul>"},{"location":"produtos/metlife_celular/","title":"Metlife Celular","text":""},{"location":"produtos/metlife_celular/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Pipeline ETL especializado para processamento de dados de seguros de celular da Metlife, realizando extra\u00e7\u00e3o do MongoDB e carregamento no PostgreSQL. Este produto apresenta caracter\u00edsticas arquiteturais espec\u00edficas que incluem projection externa personalizada e busca full avan\u00e7ada para otimiza\u00e7\u00e3o de performance.</p>"},{"location":"produtos/metlife_celular/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.metlifephone</code> (implementa\u00e7\u00e3o) e <code>implementations.metlife</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_metlife_celular</code></li> </ul>"},{"location":"produtos/metlife_celular/#singularidades-do-produto","title":"Singularidades do Produto","text":"<p>Caracter\u00edsticas \u00danicas</p> <ul> <li>Busca Full Especial: Implementa <code>busca_full=True</code> na fun\u00e7\u00e3o <code>buscar_parcelas()</code> para otimiza\u00e7\u00e3o</li> <li>Projection Externa: Utiliza arquivo <code>projection.json</code> espec\u00edfico (similar ao Disney AP)</li> <li>Logging Avan\u00e7ado: Sistema de logging mais robusto comparado a outros produtos</li> </ul>"},{"location":"produtos/metlife_celular/#processamento-de-parcelas-diferenciado","title":"Processamento de Parcelas Diferenciado","text":"<pre><code># Busca especial com par\u00e2metro busca_full\ndf_parcelas = pipe_functions.buscar_parcelas(..., busca_full=True)\n</code></pre> <p>Esta implementa\u00e7\u00e3o permite carregamento otimizado de toda a base de parcelas quando necess\u00e1rio.</p>"},{"location":"produtos/metlife_celular/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaMetlifeCelular</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador \u00fanico do bilhete <code>uuidinstallment</code> Sim \u2705 UUID da parcela <code>info_erp_transactionid</code> Sim \u2705 Identificador de transa\u00e7\u00e3o <code>number</code> Sim \u274c N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela calculado <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio <code>data_inicio_vigencia</code> Sim \u2705 Data in\u00edcio processada <code>data_fim_vigencia</code> Sim \u2705 Data fim processada <code>data_vencimento</code> Sim \u274c Data de vencimento da parcela <code>data_pagamento</code> Sim \u274c Data de pagamento da parcela <code>data_cancelamento</code> Sim \u274c Data de cancelamento, se aplic\u00e1vel <code>data_cancelamento</code> Sim \u274c Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim \u274c Data de estorno, se aplic\u00e1vel Outros campos (ex.: <code>info_dadoscliente_imei</code> Sim \u2705 IMEI do dispositivo <code>info_kakau_brand</code> Sim \u2705 Marca do aparelho <code>info_kakau_model</code> Sim \u2705 Modelo do aparelho <code>info_kakau_modelid</code> Sim \u2705 ID do modelo <code>info_kakau_storage</code> Sim \u2705 Capacidade de armazenamento <code>info_kakau_blocked</code> Sim \u2705 Status de bloqueio <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaMetlifeCelular</code>. As colunas \"Recomendado\" devem ser inclu\u00eddas quando pertinentes ao produto.</p>"},{"location":"produtos/natura_residencial/","title":"Natura Residencial","text":""},{"location":"produtos/natura_residencial/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Natura Residencial extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega no Postgres. Suporta atualiza\u00e7\u00f5es incremental (baseado em modifica\u00e7\u00f5es recentes) ou full.</p>"},{"location":"produtos/natura_residencial/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.naturaresidencial</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentesnaturaresidencial</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_natura_residencial</code></li> </ul>"},{"location":"produtos/natura_residencial/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura em duas collections: informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.naturaresidencial</code> e parcelas em <code>implementations.installmentesnaturaresidencial</code> \u2014 buscadas separadamente e depois combinadas</li> <li>Merge espec\u00edfico: a jun\u00e7\u00e3o entre infos e parcelas \u00e9 feita usando <code>left_on='info_APIsAuxiliares_ParcelaUUID'</code> e <code>right_on='uuidInstallment'</code> com <code>how='outer'</code></li> <li>Dados do im\u00f3vel: estrutura detalhada de informa\u00e7\u00f5es do im\u00f3vel segurado</li> </ul>"},{"location":"produtos/natura_residencial/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaNaturaResidencial</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> Sim \u2705 Identificador do bilhete (UUID) <code>transactionid</code> Sim \u2705 Identificador do bilhete (UUID) <code>numero</code> Sim \u2705 Identificador do bilhete (UUID) <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>data_inicio_vigencia</code> Sim \u2705 In\u00edcio da vig\u00eancia do seguro residencial <code>data_fim_vigencia</code> Sim \u2705 Fim da vig\u00eancia do seguro residencial <code>data_vencimento</code> Sim (quando houver parcelas) \u2705 Data de vencimento da parcela <code>data_pagamento</code> Opcional (relevante para concilia\u00e7\u00e3o) \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Opcional (relevante se houver cancelamento) \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Opcional (relevante para estornos) \u2705 Data de estorno da parcela <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaNaturaResidencial</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p>"},{"location":"produtos/picpay_auto/","title":"PicPay Auto","text":""},{"location":"produtos/picpay_auto/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto PicPay Auto extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega no Postgres. Suporta atualiza\u00e7\u00f5es incremental (baseado em modifica\u00e7\u00f5es recentes) ou full.</p>"},{"location":"produtos/picpay_auto/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.picpayauto</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentsppauto</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_picpay_auto</code></li> </ul>"},{"location":"produtos/picpay_auto/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura em duas collections: informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.picpayauto</code> e parcelas em <code>implementations.installmentsppauto</code> \u2014 buscadas separadamente e depois combinadas</li> <li>Merge espec\u00edfico: a jun\u00e7\u00e3o entre infos e parcelas \u00e9 feita usando <code>left_on='info_APIsAuxiliares_ParcelaUUID'</code> e <code>right_on='uuidInstallment'</code> com <code>how='outer'</code></li> <li>Filtro de status: considera apenas ap\u00f3lices com status 'Ativa' e 'Cancelada' (filtro aplicado em ambas collections)</li> <li>Expans\u00e3o de coberturas: utiliza fun\u00e7\u00e3o <code>expandir_coberturas_para_colunas</code> que converte array de coberturas em colunas individuais (0-6)</li> </ul> <p>Especificidades T\u00e9cnicas</p> <ul> <li>Sistema de coberturas: array complexo expandido para 7 grupos de colunas (franquia, IS, pr\u00eamios)</li> </ul>"},{"location":"produtos/picpay_auto/#campos-principais","title":"Campos Principais","text":""},{"location":"produtos/picpay_auto/#sistema-de-coberturas-automotivas","title":"Sistema de Coberturas Automotivas","text":"<p>O PicPay Auto possui sistema robusto de 7 coberturas (0-6), cada uma com campos espec\u00edficos:</p> <p>Para cada cobertura (0 a 6):</p> <ul> <li><code>info_cobertura_X_code</code>: C\u00f3digo da cobertura</li> <li><code>info_cobertura_X_nome</code>: Nome da cobertura  </li> <li><code>info_cobertura_X_franquia</code>: Valor da franquia (float)</li> <li><code>info_cobertura_X_is</code>: Import\u00e2ncia segurada (float)</li> <li><code>info_cobertura_X_premionet</code>: Pr\u00eamio l\u00edquido (float)</li> <li><code>info_cobertura_X_premiotarifario</code>: Pr\u00eamio tarif\u00e1rio (float)</li> <li><code>info_cobertura_X_idprodutocobertura</code>: ID do produto da cobertura</li> </ul>"},{"location":"produtos/picpay_auto/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaPicPayAuto</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> Sim \u2705 Identificador da parcela (UUID) <code>transactionid</code> Sim \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>numero</code> Sim \u2705 N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>data_inicio</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_cancelamento</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 <code>data_pagamento</code> Opcional (relevante para concilia\u00e7\u00e3o) \u2705 Data de pagamento da parcela <code>data_estorno</code> Opcional (relevante para estornos) \u2705 Data de estorno da parcela <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaPicPayAuto</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p> <p>Especificidades do PicPay Auto</p> <ul> <li>Filtro de status: apenas ap\u00f3lices 'Ativa' e 'Cancelada' s\u00e3o processadas</li> <li>Dados do ve\u00edculo: estrutura detalhada exclusiva para seguro automotivo</li> <li>Sistema de coberturas: 7 coberturas expandidas em colunas individuais via fun\u00e7\u00e3o espec\u00edfica</li> <li>Expans\u00e3o complexa: fun\u00e7\u00e3o <code>expandir_coberturas_para_colunas</code> processa array aninhado</li> </ul>"},{"location":"produtos/picpay_cyber/","title":"PicPay Cyber","text":""},{"location":"produtos/picpay_cyber/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto PicPay Cyber extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega em duas tabelas Postgres separadas. Suporta atualiza\u00e7\u00e3o full.</p>"},{"location":"produtos/picpay_cyber/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.cyberpicpay</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentsgeneric</code> (parcelas)</li> <li>Destino: Duas Tabelas Postgres <code>innoveo_picpay_cyber_infos</code> e <code>innoveo_picpay_cyber_parcelas</code></li> </ul>"},{"location":"produtos/picpay_cyber/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Arquitetura dupla: \u00daNICO produto que separa dados em duas tabelas Postgres distintas - uma para informa\u00e7\u00f5es e outra para parcelas</li> <li>Schemas m\u00faltiplos: utiliza tr\u00eas schemas Pandera diferentes (<code>SchemaPicpayCyber</code>, <code>SchemaPicpayCyberInfos</code>, <code>SchemaPicpayCyberParcelas</code>)</li> <li>Fun\u00e7\u00e3o especial: <code>gerar_base_para_busca_somente_parcelas()</code> - busca apenas collection de parcelas (n\u00e3o existe em outros produtos)</li> <li>Paths separados: <code>PATH_STAGE_INFOS</code> e <code>PATH_STAGE_PARCELAS</code> para processamento independente</li> </ul> <p>Arquitetura \u00danica</p> <ul> <li>Duas tabelas de destino: separa\u00e7\u00e3o completa entre dados de implementa\u00e7\u00e3o e parcelas</li> <li>\u00cdndices espec\u00edficos: cada tabela tem seu pr\u00f3prio conjunto de \u00edndices otimizados</li> <li>Logging avan\u00e7ado: sistema de logging mais robusto com diferentes n\u00edveis</li> </ul>"},{"location":"produtos/picpay_cyber/#funcionalidades-especiais","title":"Funcionalidades Especiais","text":""},{"location":"produtos/picpay_cyber/#exemplo-de-uso","title":"Exemplo de Uso","text":"Source code in pipeline_picpay_cyber_funcoes.py <pre><code># Fun\u00e7\u00e3o exclusiva do PicPay Cyber - busca apenas collection de parcelas\ntp_att, bilhetes = piccyber.gerar_base_para_busca_somente_parcelas(\n    ambiente=AMBIENTE_MONGO,\n    qde_dias_retroativos=QDE_DIAS_RETROATIVOS,\n    percentual_modificacao_incremental=PERCENTUAL_MODIFICACAO_INCREMENTAL,\n    tp_atualizacao=TP_ATUALIZACAO\n)\n\n# Processamento Duplo - fun\u00e7\u00e3o especial que retorna duas estruturas de dados\ndf_fim_info, df_fim_parcelas = piccyber.buscar_dados_bilhetes_info_parcelas(\n    ambiente=AMBIENTE_MONGO,\n    data=data,\n    lotes_querys_parcelas=pipelines_parcelas_cyber,\n    lotes_querys_informacoes=pipelines_infos_cyber\n)\n</code></pre>"},{"location":"produtos/picpay_cyber/#sistema-de-indices-diferenciado","title":"Sistema de \u00cdndices Diferenciado","text":"<p>\u00cdndices da Tabela de Infos: - <code>idx_innoveo_picpay_cyber_infos_uuid_bilhete</code> - <code>idx_innoveo_picpay_cyber_infos_bilhete</code></p> <p>\u00cdndices da Tabela de Parcelas: - <code>idx_innoveo_picpay_cyber_parcelas_uuid_bilhete</code> - <code>idx_innoveo_picpay_cyber_parcelas_uuidinstallment</code> - <code>idx_innoveo_picpay_cyber_parcelas_certificate</code> - <code>idx_innoveo_picpay_cyber_parcelas_data_pagamento</code> - <code>idx_innoveo_picpay_cyber_parcelas_data_vencimento</code></p>"},{"location":"produtos/picpay_cyber/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/picpay_cyber/#tabela-de-informacoes-innoveo_picpay_cyber_infos","title":"Tabela de Informa\u00e7\u00f5es (innoveo_picpay_cyber_infos)","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaPicpayCyberInfos</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>info_quotecounter</code> Sim \u2705 Contador de cota\u00e7\u00e3o <code>info_policystartdate</code> Sim \u2705 In\u00edcio da vig\u00eancia do seguro cyber <code>info_policyexpirationdate</code> Sim \u2705 Fim da vig\u00eancia do seguro cyber <code>info_picpaycertificate_cpf</code> Espec\u00edfico Cyber \u2705 CPF do certificado PicPay <code>info_picpaycertificate_email_certificate</code> Espec\u00edfico Cyber \u2705 Email do certificado <code>info_erp_cdapolice</code> Espec\u00edfico Cyber \u2705 C\u00f3digo da ap\u00f3lice no ERP <code>info_fif_fifquote</code> Espec\u00edfico Cyber \u2705 Cota\u00e7\u00e3o FIF <code>info_picpay_comissionfee</code> Espec\u00edfico Cyber \u2705 Taxa de comiss\u00e3o PicPay <code>info_capitalization_lucknumber</code> Espec\u00edfico Cyber \u2705 N\u00famero da sorte para capitaliza\u00e7\u00e3o"},{"location":"produtos/picpay_cyber/#tabela-de-parcelas-innoveo_picpay_cyber_parcelas","title":"Tabela de Parcelas (innoveo_picpay_cyber_parcelas)","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaPicpayCyberParcelas</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>certificate</code> Sim \u2705 Certificado da parcela <code>uuidinstallment</code> Sim \u2705 UUID da parcela <code>duedate</code> Sim \u2705 Data de vencimento <code>number</code> Sim \u2705 N\u00famero da parcela <code>status</code> Sim \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio <p>Observa\u00e7\u00e3o sobre Schemas</p> <p>O PicPay Cyber utiliza tr\u00eas schemas diferentes: um para dados combinados, um espec\u00edfico para infos e outro para parcelas. Todas as colunas listadas como \"Sim\" devem estar presentes nos respectivos schemas.</p>"},{"location":"produtos/picpay_phone/","title":"PicPay Phone","text":""},{"location":"produtos/picpay_phone/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto PicPay Phone extrai dados de duas collections no MongoDB espec\u00edficas para seguros de celular, aplica transforma\u00e7\u00f5es especializadas (incluindo valida\u00e7\u00e3o de IMEI, dados de dispositivo m\u00f3vel) e carrega em uma \u00fanica tabela Postgres. Suporta atualiza\u00e7\u00f5es incremental, full e din\u00e2mica baseada em modifica\u00e7\u00f5es.</p>"},{"location":"produtos/picpay_phone/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.phonepicpay</code> (implementa\u00e7\u00e3o) e <code>implementations.phoneinstallments</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_picpay_phone</code></li> </ul>"},{"location":"produtos/picpay_phone/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas de Telefonia</p> <ul> <li>Dados de dispositivo m\u00f3vel: campos especializados para marca, modelo, IMEI e valida\u00e7\u00e3o de celulares</li> <li>Estrutura Multibrick: utiliza <code>InstallmentMultibrick</code> com explode para normalizar dados de parcelas</li> </ul>"},{"location":"produtos/picpay_phone/#dados-especificos-do-dispositivo-phonedata","title":"Dados Espec\u00edficos do Dispositivo (PhoneData)","text":""},{"location":"produtos/picpay_phone/#identificacao-do-aparelho","title":"Identifica\u00e7\u00e3o do Aparelho:","text":"<ul> <li>Marca e Modelo: <code>info_phonedata_brand</code>, <code>info_phonedata_model</code>, <code>info_phonedata_model_id</code></li> <li>Identifica\u00e7\u00e3o: <code>info_phonedata_imei</code>, <code>info_phonedata_imeidate</code></li> <li>Categoria: <code>info_phonedata_flag</code></li> </ul>"},{"location":"produtos/picpay_phone/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/picpay_phone/#dados-essenciais","title":"Dados Essenciais","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaPicpayPhone</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 UUID da parcela <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u2705 N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio (calculado com f\u00f3rmula espec\u00edfica) <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u2705 Data de estorno <p>Especificidades do PicPay Phone</p> <ul> <li>Foco em dispositivos m\u00f3veis: \u00fanico produto com dados espec\u00edficos de celular (marca, modelo, IMEI)</li> </ul>"},{"location":"produtos/picpay_residencial/","title":"PicPay Residencial","text":""},{"location":"produtos/picpay_residencial/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto PicPay Residencial extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e carrega no Postgres. Suporta atualiza\u00e7\u00f5es incremental (baseado em modifica\u00e7\u00f5es recentes) ou full.</p>"},{"location":"produtos/picpay_residencial/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.picpayresidencial</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentesppresidencial</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_picpay_residencial</code></li> </ul>"},{"location":"produtos/picpay_residencial/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura em duas collections: informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.picpayresidencial</code> e parcelas em <code>implementations.installmentesppresidencial</code> </li> <li>Merge espec\u00edfico: a jun\u00e7\u00e3o entre infos e parcelas \u00e9 feita usando <code>left_on='info_APIsAuxiliares_ParcelaUUID'</code> e <code>right_on='uuidInstallment'</code> com <code>how='outer'</code></li> <li>Dados do im\u00f3vel: estrutura detalhada de informa\u00e7\u00f5es do im\u00f3vel segurado</li> </ul>"},{"location":"produtos/picpay_residencial/#campos-principais","title":"Campos Principais","text":""},{"location":"produtos/picpay_residencial/#dados-especificos-do-imovel","title":"Dados Espec\u00edficos do Im\u00f3vel","text":"<p>Estrutura completa para caracteriza\u00e7\u00e3o do im\u00f3vel segurado:</p> <ul> <li>Localiza\u00e7\u00e3o: </li> <li><code>info_dadoscliente_dadosimovel_endereco</code>: Endere\u00e7o do im\u00f3vel</li> <li><code>info_dadoscliente_dadosimovel_endereconumero</code>: N\u00famero do endere\u00e7o</li> <li><code>info_dadoscliente_dadosimovel_complemento</code>: Complemento</li> <li><code>info_dadoscliente_dadosimovel_bairro</code>: Bairro do im\u00f3vel</li> <li><code>info_dadoscliente_dadosimovel_cidade</code>: Cidade do im\u00f3vel</li> <li><code>info_dadoscliente_dadosimovel_estadosigla</code>: Estado do im\u00f3vel</li> <li><code>info_dadoscliente_dadosimovel_cep</code>: CEP do im\u00f3vel</li> </ul>"},{"location":"produtos/picpay_residencial/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaPicPayResidencial</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> Sim \u2705 Identificador do parcela (UUID) <code>transactionid</code> Sim \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>numero</code> Recomendado \u2705 N\u00famero da parcela <code>status</code> Recomendado \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u2705 Data de estorno <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaPicPayResidencial</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p>"},{"location":"produtos/sem_parar/","title":"Sem Parar","text":""},{"location":"produtos/sem_parar/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Sem Parar extrai dados de duas collections no MongoDB espec\u00edficas para seguros automotivos, aplica transforma\u00e7\u00f5es especializadas (incluindo dados completos de ve\u00edculos, informa\u00e7\u00f5es do segurado e classifica\u00e7\u00e3o VIP) e carrega em uma \u00fanica tabela Postgres. Suporta atualiza\u00e7\u00f5es incremental, full e din\u00e2mica baseada em modifica\u00e7\u00f5es.</p>"},{"location":"produtos/sem_parar/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.autosemparar</code> (implementa\u00e7\u00e3o) e <code>implementations.installmentssemparargeneric</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_semparar</code></li> </ul>"},{"location":"produtos/sem_parar/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas de Seguros Automotivos</p> <ul> <li>Dados automotivos completos: campos espec\u00edficos para ve\u00edculos com FIPE, chassi, placa, renavam e dados do fabricante</li> <li>FIF Sem Parar: campo espec\u00edfico do produto para controle interno</li> <li>RiskData expandido: dados completos de risco automotivo incluindo categoria de ve\u00edculo</li> </ul>"},{"location":"produtos/sem_parar/#validacoes-especificas-automotivas","title":"Valida\u00e7\u00f5es Espec\u00edficas Automotivas","text":"<p>O produto inclui valida\u00e7\u00f5es espec\u00edficas para:</p> <ul> <li> <p>Dados FIPE: valida\u00e7\u00e3o de c\u00f3digos de ve\u00edculos</p> </li> <li> <p>Chassi e Renavam: valida\u00e7\u00e3o de documenta\u00e7\u00e3o veicular</p> </li> <li> <p>Anos de fabrica\u00e7\u00e3o: valida\u00e7\u00e3o de datas automotivas</p> </li> <li> <p>Categoria de ve\u00edculo: valida\u00e7\u00e3o de tipos automotivos</p> </li> <li> <p>CPF auxiliar: valida\u00e7\u00e3o adicional de documenta\u00e7\u00e3o</p> </li> </ul>"},{"location":"produtos/sem_parar/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/sem_parar/#dados-essenciais","title":"Dados Essenciais","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaSemParar</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 UUID da parcela <code>trnasactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u2705 N\u00famero da parcela <code>status</code> Sim \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio <code>comission</code> Recomendado \u2705 Comiss\u00e3o espec\u00edfica na parcela <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento da parcela <code>data_estorno</code> Sim \u2705 Data de estorno do bilhete"},{"location":"produtos/sem_parar/#dados-especificos-automotivos","title":"Dados Espec\u00edficos Automotivos","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaSemParar</code> Observa\u00e7\u00f5es <code>info_riskdata_fipe</code> Espec\u00edfico Sem Parar \u2705 C\u00f3digo FIPE do ve\u00edculo <code>info_riskdata_chassi</code> Espec\u00edfico Sem Parar \u2705 Chassi do ve\u00edculo <code>info_riskdata_licenceplate</code> Espec\u00edfico Sem Parar \u2705 Placa do ve\u00edculo <code>info_riskdata_renavam</code> Espec\u00edfico Sem Parar \u2705 C\u00f3digo RENAVAM <code>info_riskdata_manufacturer</code> Espec\u00edfico Sem Parar \u2705 Fabricante do ve\u00edculo <code>info_riskdata_model</code> Espec\u00edfico Sem Parar \u2705 Modelo do ve\u00edculo <code>info_riskdata_vehiclecategory</code> Espec\u00edfico Sem Parar \u2705 Categoria do ve\u00edculo <code>info_vip</code> Espec\u00edfico Sem Parar \u2705 Classifica\u00e7\u00e3o VIP do cliente <code>info_tipocompra</code> Espec\u00edfico Sem Parar \u2705 Tipo de aquisi\u00e7\u00e3o do seguro <code>info_fif_semparar</code> Espec\u00edfico Sem Parar \u2705 FIF espec\u00edfico do produto <p>Especificidades do Sem Parar</p> <ul> <li>Foco automotivo: produto com dados completos de ve\u00edculos (FIPE, chassi, placa, renavam)</li> <li>RiskData expandido: dados completos de risco automotivo incluindo categoria de ve\u00edculo</li> <li>M\u00faltiplas comiss\u00f5es: separa\u00e7\u00e3o entre ag\u00eancia, corretor e comiss\u00e3o da parcela</li> </ul> <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaSemParar</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p>"},{"location":"produtos/sem_parar_autodiario/","title":"Sem Parar Autodi\u00e1rio","text":""},{"location":"produtos/sem_parar_autodiario/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Sem Parar Autodi\u00e1rio extrai dados de duas collections no MongoDB espec\u00edficas para seguros automotivos di\u00e1rios, aplica transforma\u00e7\u00f5es especializadas (incluindo dados de ativa\u00e7\u00e3o, per\u00edodos de cobertura e pricing expandido) e carrega em uma \u00fanica tabela Postgres. Suporta atualiza\u00e7\u00f5es incremental, full e din\u00e2mica baseada em modifica\u00e7\u00f5es.</p>"},{"location":"produtos/sem_parar_autodiario/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li> <p>Fonte: MongoDB (produ\u00e7\u00e3o)  </p> </li> <li> <p>Collections: <code>implementations.autosemparardiario</code> (implementa\u00e7\u00e3o) e <code>implementations.autosemparardiarioativacaogeneric</code> (ativa\u00e7\u00f5es)</p> </li> <li> <p>Destino: Tabela Postgres <code>innoveo_semparar_autodiario</code></p> </li> </ul>"},{"location":"produtos/sem_parar_autodiario/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas de Seguro Di\u00e1rio</p> <ul> <li>Seguro di\u00e1rio: \u00daNICO produto com cobertura automotiva por per\u00edodos di\u00e1rios espec\u00edficos</li> <li>Estrutura de ativa\u00e7\u00e3o: trabalha com ativa\u00e7\u00f5es diretas sem InstallmentMultibrick</li> <li>Collections ativa\u00e7\u00e3o: <code>autosemparardiarioativacaogeneric</code> espec\u00edfica para controle de ativa\u00e7\u00f5es di\u00e1rias</li> <li>Merge inner espec\u00edfico: gera base atrav\u00e9s de merge entre implementa\u00e7\u00e3o e ativa\u00e7\u00f5es (n\u00e3o outer join)</li> <li>Confirmation DueDate: campo espec\u00edfico para confirma\u00e7\u00e3o de ativa\u00e7\u00e3o de cobertura</li> <li>Dados temporais: StartDate, EndDate, ReceivedDate para controle de per\u00edodos de cobertura</li> </ul>"},{"location":"produtos/sem_parar_autodiario/#funcionalidades-especiais","title":"Funcionalidades Especiais","text":""},{"location":"produtos/sem_parar_autodiario/#estrutura-de-ativacao-diaria","title":"Estrutura de Ativa\u00e7\u00e3o Di\u00e1ria","text":"<p>Produto trabalha com ativa\u00e7\u00f5es diretas :</p> Source code in pipeline_sem_parar_autodiario_funcoes.py <pre><code># Merge espec\u00edfico entre implementa\u00e7\u00e3o e ativa\u00e7\u00f5es (inner join)\ndf_base = df_implementacao.merge(\n    df_parcelas[['uuid_bilhete', 'uuid_parcela', 'uuid_parcelas_binary', 'data_modificacao']], \n    how='inner', \n    on='uuid_bilhete', \n    suffixes = ['_adesao', '_ativacoes']\n)\n\n# Controle de \u00faltima modifica\u00e7\u00e3o entre ades\u00e3o e ativa\u00e7\u00f5es\ndf_auxiliar = df_base.groupby('uuid_bilhete').agg({\n    'data_modificacao_adesao': max, \n    'data_modificacao_ativacoes': max\n}).reset_index()\n\n# Sem explode - dados diretos de ativa\u00e7\u00e3o\ndf['VALOR_PARCELA'] = fc.converter_coluna_para_numerico(df, 'SaleValue')\ndf['VALOR_TARIFARIO'] = round((df['VALOR_PARCELA'] / (107.38))*100,2)\n</code></pre>"},{"location":"produtos/sem_parar_autodiario/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/sem_parar_autodiario/#dados-essenciais","title":"Dados Essenciais","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaSemPararAutoDiario</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 UUID da ativa\u00e7\u00e3o (n\u00e3o parcela) <code>transactionid</code> Sim \u274c Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u274c N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 N\u00famero da parcela <code>valor_tarifario</code> Sim \u2705 N\u00famero da parcela <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u274c Data de pagamento <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u274c Data de estorno do bilhete/ap\u00f3lice n\u00e3o esta presente no MongoDB <p>Ativa\u00e7\u00f5es vs Parcelas</p> <p>O Sem Parar Autodi\u00e1rio trabalha com \"ativa\u00e7\u00f5es\" de cobertura di\u00e1ria ao inv\u00e9s de parcelas tradicionais. Cada ativa\u00e7\u00e3o representa um per\u00edodo espec\u00edfico de cobertura.</p> <p>Especificidades do Sem Parar Autodi\u00e1rio</p> <ul> <li>Cobertura di\u00e1ria: \u00daNICO produto com seguros automotivos de curta dura\u00e7\u00e3o (per\u00edodos espec\u00edficos)</li> <li>Estrutura ativa\u00e7\u00e3o: trabalha com ativa\u00e7\u00f5es ao inv\u00e9s de parcelas tradicionais</li> <li>Sem Multibrick: n\u00e3o utiliza InstallmentMultibrick, processamento direto de ativa\u00e7\u00f5es</li> <li>Merge inner espec\u00edfico: garante que s\u00f3 processa bilhetes com ativa\u00e7\u00f5es confirmadas</li> <li>Pricing expandido: m\u00faltiplas comiss\u00f5es e valores espec\u00edficos para seguro di\u00e1rio</li> </ul>"},{"location":"produtos/sem_parar_prestamista/","title":"Sem Parar Prestamista","text":""},{"location":"produtos/sem_parar_prestamista/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Sem Parar Prestamista extrai dados de uma collection principal no MongoDB, aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es)  .</p>"},{"location":"produtos/sem_parar_prestamista/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collection: <code>implementations.prestamistasp</code> (implementa\u00e7\u00e3o \u00fanica)</li> <li>Destino: Tabela Postgres (<code>innoveo_semparar_prestamista</code>)</li> </ul>"},{"location":"produtos/sem_parar_prestamista/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Collection \u00fanica: busca apenas informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.prestamistasp</code> - N\u00c3O faz merge com parcelas</li> </ul>"},{"location":"produtos/sem_parar_prestamista/#campos-especificos","title":"Campos Especificos","text":""},{"location":"produtos/sem_parar_prestamista/#coberturas-detalhadas","title":"Coberturas Detalhadas:","text":"<p>Morte: - <code>info_informacoes_mortecapital</code>, <code>info_informacoes_mortenet</code>, <code>info_informacoes_mortetarif</code></p> <p>Funeral: - <code>info_informacoes_funeralcapital</code>, <code>info_informacoes_funeralnet</code>, <code>info_informacoes_funeraltarif</code></p> <p>IPTA (Invalidez Permanente Total por Acidente): - <code>info_informacoes_iptacapital</code>, <code>info_informacoes_iptanet</code>, <code>info_informacoes_iptatarif</code></p> <p>PRD (Prote\u00e7\u00e3o Residencial Danos): - <code>info_informacoes_prdcapital</code>, <code>info_informacoes_prdnet</code>, <code>info_informacoes_prdtarif</code></p> <p>PRI (Prote\u00e7\u00e3o Residencial Inc\u00eandio): - <code>info_informacoes_pricapital</code>, <code>info_informacoes_prinet</code>, <code>info_informacoes_pritarif</code></p> <p>Sorteio/Capitaliza\u00e7\u00e3o: - <code>info_informacoes_sorteiocapital</code>, <code>info_informacoes_sorteionet</code>, <code>info_informacoes_sorteiotarif</code></p> <p>DMHO (Danos Morais e F\u00edsicos): - <code>info_informacoes_dmhocapital</code>, <code>info_informacoes_dmhonet</code>, <code>info_informacoes_dmhotarif</code>, <code>info_informacoes_dmhoativa</code></p>"},{"location":"produtos/sem_parar_prestamista/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaSemPararPrestamista</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> Sim \u274c N\u00e3o possui parcelas <code>transactionid</code> Sim \u274c N\u00e3o possui parcelas <code>number</code> Sim \u274c N\u00e3o possui parcelas <code>valor_parcela</code> Sim \u274c <code>valor_tarifario</code> Sim \u274c <code>data_inicio_vigencia</code> Sim \u2705 In\u00edcio da vig\u00eancia do seguro prestamista <code>data_fim_vigencia</code> Sim \u2705 Fim da vig\u00eancia do seguro prestamista <code>data_vencimento</code> Opcional (relevante para parcelas) \u2705 Data de vencimento <code>data_pagamento</code> Sim \u274c <code>data_cancelamento</code> Sim \u274c <code>data_estorno</code> Sim \u274c <code>info_cancel_cancelstatus</code> Espec\u00edfico Prestamista \u2705 Status de cancelamento <code>info_informacoes_statussegurado</code> Espec\u00edfico Prestamista \u2705 Status do segurado <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaSemPararPrestamista</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p> <p>Especificidades do Sem Parar Prestamista</p> <ul> <li>Coberturas m\u00faltiplas: 7 tipos de coberturas (morte, funeral, IPTA, PRD, PRI, sorteio, DMHO)</li> <li>Sem parcelas: n\u00e3o processa collection de parcelas separada</li> </ul>"},{"location":"produtos/sem_parar_viagem/","title":"Sem Parar Viagem","text":""},{"location":"produtos/sem_parar_viagem/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Sem Parar Viagem extrai dados de duas collections no MongoDB (uma de \"implementa\u00e7\u00e3o\"/\"infos\" e uma de \"parcelas\" separada), aplica transforma\u00e7\u00f5es (limpeza, convers\u00f5es de tipos, valida\u00e7\u00f5es) e gera arquivos CSV.</p>"},{"location":"produtos/sem_parar_viagem/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.pppsempararviagem</code> (implementa\u00e7\u00e3o) e `implementations.</li> <li>Destino: Tabela Postgres (<code>innoveo_semparar_viagem</code>)</li> </ul>"},{"location":"produtos/sem_parar_viagem/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas</p> <ul> <li>Estrutura simplificada: busca apenas informa\u00e7\u00f5es da implementa\u00e7\u00e3o em <code>implementations.pppsempararviagem</code> - N\u00c3O faz merge com parcelas</li> <li>Merge por bilhete: utiliza <code>uuid_bilhete</code> ao inv\u00e9s de <code>uuid_parcela</code> no <code>drop_duplicates</code> da fun\u00e7\u00e3o <code>gerar_base_para_busca</code></li> <li>Parcelas internas: os dados de parcela est\u00e3o dentro da pr\u00f3pria collection de implementa\u00e7\u00e3o (campo <code>Parcela</code>)</li> </ul> <p>Arquitetura Diferenciada</p> <ul> <li>Sem buscar_parcelas(): fun\u00e7\u00e3o <code>buscar_dados_bilhetes</code> n\u00e3o chama <code>buscar_parcelas</code> como nos outros produtos</li> <li>Apenas infos: processa somente <code>buscar_infos_bilhetes</code> </li> </ul>"},{"location":"produtos/sem_parar_viagem/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaSemPararViagem</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>number</code> Recomendado \u2705 N\u00famero da parcela <code>data_inicio_vigencia</code> Sim \u2705 In\u00edcio da vig\u00eancia do seguro viagem <code>data_fim_vigencia</code> Sim \u2705 Fim da vig\u00eancia do seguro viagem <code>data_vencimento</code> Sim (quando houver parcelas) \u2705 Data de vencimento da parcela <code>data_pagamento</code> Opcional (relevante para concilia\u00e7\u00e3o) \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Opcional (relevante se houver cancelamento) \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Opcional (relevante para estornos) \u2705 Data de estorno da parcela <code>info_dadosapolice_premiotarifario</code> Espec\u00edfico Viagem \u2705 Pr\u00eamio tarif\u00e1rio da ap\u00f3lice <code>info_dadosapolice_premiomensal</code> Espec\u00edfico Viagem \u2705 Pr\u00eamio mensal <code>info_dadosapolice_premioliquido</code> Espec\u00edfico Viagem \u2705 Pr\u00eamio l\u00edquido <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaSemPararViagem</code>. As colunas \"Opcional\" devem ser inclu\u00eddas apenas quando pertinentes ao produto.</p> <p>Especificidades do Sem Parar Viagem</p> <ul> <li>Sem merge de parcelas: parcelas est\u00e3o integradas na collection de implementa\u00e7\u00e3o</li> <li>Arquitetura simplificada: <code>buscar_dados_bilhetes</code> processa apenas infos (n\u00e3o faz merge)</li> </ul>"},{"location":"produtos/telefonica_cyber/","title":"Telefonica Cyber","text":""},{"location":"produtos/telefonica_cyber/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Pipeline ETL especializado para processamento de dados de seguros cyber da Telefonica, realizando extra\u00e7\u00e3o do MongoDB e carregamento no PostgreSQL. Este produto destaca-se por ser focado exclusivamente em seguros de prote\u00e7\u00e3o cibern\u00e9tica, incorporando campos espec\u00edficos para atividades de risco, dados banc\u00e1rios e informa\u00e7\u00f5es de cyber ataques.</p>"},{"location":"produtos/telefonica_cyber/#especificacoes-tecnicas","title":"Especifica\u00e7\u00f5es T\u00e9cnicas","text":""},{"location":"produtos/telefonica_cyber/#collections-mongodb","title":"Collections MongoDB","text":"Collection Uso Observa\u00e7\u00e3o <code>implementations.telefonicacyber</code> \u00danica collection Produto sem parcelas separadas"},{"location":"produtos/telefonica_cyber/#estrutura-de-dados","title":"Estrutura de Dados","text":"<p>Arquitetura Singular: Produto sem collection de parcelas separada - todas as informa\u00e7\u00f5es de parcelas s\u00e3o processadas via unwind do array <code>Pagamento.Parcelas</code> dentro da pr\u00f3pria collection principal.</p>"},{"location":"produtos/telefonica_cyber/#singularidades-do-produto","title":"Singularidades do Produto","text":"<p>Caracter\u00edsticas \u00danicas</p> <ul> <li>Sem Collection de Parcelas: \u00danico produto que n\u00e3o utiliza collection separada para parcelas</li> </ul>"},{"location":"produtos/telefonica_cyber/#arquitetura-de-collection-unica","title":"Arquitetura de Collection \u00danica","text":"<p>Diferentemente de outros produtos que utilizam duas collections (certificados + parcelas), o Telefonica Cyber processa tudo em uma \u00fanica collection:</p> <pre><code># Sem COLLECTION_PARCELAS definida\n# Processamento via unwind interno:\n{\n    \"$unwind\": {\n        \"path\": \"$Pagamento.Parcelas\",\n        \"preserveNullAndEmptyArrays\": True\n    }\n}\n</code></pre>"},{"location":"produtos/telefonica_cyber/#apis-telefonica-especificas","title":"APIs Telefonica Espec\u00edficas","text":"<ul> <li>APIsAuxiliares_ApisTelefonica_BudgetID: ID espec\u00edfico da API Telefonica</li> <li>APIsAuxiliares_ApisTelefonica_PolicyId: ID da ap\u00f3lice na API Telefonica</li> <li>retornoTelefonicaCancel: Resposta espec\u00edfica de cancelamento</li> </ul>"},{"location":"produtos/telefonica_cyber/#filtro-inteligente-de-parcelas","title":"Filtro Inteligente de Parcelas","text":"<p>Implementa l\u00f3gica sofisticada para filtrar parcelas v\u00e1lidas:</p> <pre><code># Mant\u00e9m 1 linha vazia se todas vazias; remove vazias se houver v\u00e1lidas\nmask_validos = df_fim.groupby(\"uuid_bilhete\")[num_col].transform(lambda x: (x != \"\").any())\ndf_filtrado = df_fim[~(mask_validos &amp; (df_fim[num_col] == \"\"))].copy()\n</code></pre>"},{"location":"produtos/telefonica_cyber/#campos-obrigatorios","title":"Campos Obrigat\u00f3rios","text":""},{"location":"produtos/telefonica_cyber/#campos-de-identificacao","title":"Campos de Identifica\u00e7\u00e3o","text":"<ul> <li><code>uuid_bilhete</code>: Identificador \u00fanico do bilhete</li> <li><code>info_numeroproposta</code>: N\u00famero da proposta</li> <li><code>info_productkey</code>: Chave do produto</li> <li><code>info_erpref</code>: Refer\u00eancia ERP</li> </ul>"},{"location":"produtos/telefonica_cyber/#dados-da-empresa-cliente","title":"Dados da Empresa (Cliente)","text":"<ul> <li><code>info_dadoscliente_cnpj</code>: CNPJ da empresa segurada</li> <li><code>info_dadoscliente_nomeemp</code>: Nome da empresa</li> <li><code>info_dadoscliente_faturamentoapi</code>: Faturamento via API</li> <li><code>info_dadoscliente_faturamentovalor</code>: Valor do faturamento</li> <li><code>info_dadoscliente_atividadecodigo</code>: C\u00f3digo da atividade</li> <li><code>info_dadoscliente_atividadesetor</code>: Setor de atividade</li> </ul>"},{"location":"produtos/telefonica_cyber/#dados-cyber","title":"Dados Cyber","text":"<ul> <li><code>info_dadoscliente_sofreucyberataque</code>: Hist\u00f3rico de cyber ataques</li> <li><code>info_dadoscliente_tiposciberataque</code>: Tipos de ataques sofridos</li> <li><code>info_dadoscliente_atividadeperigosa</code>: Classifica\u00e7\u00e3o de risco</li> </ul>"},{"location":"produtos/telefonica_cyber/#dados-bancarios","title":"Dados Banc\u00e1rios","text":"<ul> <li><code>info_dadoscliente_contabancaria</code>: N\u00famero da conta</li> <li><code>info_dadoscliente_containstituicao</code>: Banco</li> <li><code>info_dadoscliente_contadigito</code>: D\u00edgito verificador</li> <li><code>info_dadoscliente_contaagencia</code>: Ag\u00eancia</li> </ul>"},{"location":"produtos/telefonica_cyber/#dados-de-pagamento","title":"Dados de Pagamento","text":"<ul> <li><code>info_pagamento_parcelas_numero</code>: N\u00famero da parcela</li> <li><code>info_pagamento_parcelas_valor</code>: Valor da parcela</li> <li><code>info_pagamento_parcelas_status</code>: Status do pagamento</li> <li><code>info_pagamento_parcelas_datavencimento</code>: Data de vencimento</li> <li><code>info_pagamento_transacaoid</code>: ID da transa\u00e7\u00e3o</li> <li><code>info_pagamento_metodopagamento</code>: M\u00e9todo de pagamento</li> </ul>"},{"location":"produtos/telefonica_cyber/#apis-telefonica","title":"APIs Telefonica","text":"<ul> <li><code>info_apisauxiliares_apistelefonica_budgetid</code>: Budget ID Telefonica</li> <li><code>info_apisauxiliares_apistelefonica_policyid</code>: Policy ID Telefonica</li> </ul>"},{"location":"produtos/telefonica_cyber/#dados-temporais","title":"Dados Temporais","text":"<ul> <li><code>info_iniciovigencia</code>: Data in\u00edcio vig\u00eancia</li> <li><code>info_fimvigencia</code>: Data fim vig\u00eancia</li> <li><code>data_inicio_vigencia</code>: Data in\u00edcio processada</li> <li><code>data_fim_vigencia</code>: Data fim processada</li> <li><code>data_vencimento</code>: Data vencimento da parcela</li> <li><code>data_pagamento</code>: Data do pagamento</li> <li><code>data_atualizacao</code>: Timestamp de processamento</li> </ul>"},{"location":"produtos/telefonica_cyber/#checklist-de-validacao","title":"Checklist de Valida\u00e7\u00e3o","text":""},{"location":"produtos/telefonica_cyber/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaKovrAP</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>installmentsuuid</code> Sim \u274c Identificador do parcela (UUID) <code>transactionid</code> Recomendado \u274c Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u274c N\u00famero da parcela <code>valor_parcela</code> Sim \u2705 <code>valor_tarifario</code> Sim \u2705 <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u274c Data de estorno Outros campos de comiss\u00e3o (ex.: <code>info_infokovr_commissionsisou</code>) Recomendado \u2705 <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaTelefonicaCyber</code>. </p>"},{"location":"produtos/willbank_carteira/","title":"Willbank Carteira","text":""},{"location":"produtos/willbank_carteira/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Willbank Carteira extrai dados de duas collections no MongoDB espec\u00edficas para seguros de carteira digital, aplica transforma\u00e7\u00f5es especializadas (incluindo dados expandidos de cliente e produtos financeiros) e carrega em uma \u00fanica tabela Postgres. Suporta atualiza\u00e7\u00f5es incremental, full e din\u00e2mica baseada em modifica\u00e7\u00f5es.</p>"},{"location":"produtos/willbank_carteira/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.willbank</code> (implementa\u00e7\u00e3o) e <code>implementations.willbankinstallments</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_willbank_carteira</code></li> </ul>"},{"location":"produtos/willbank_carteira/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas de Carteira Digital</p> <ul> <li>Dados de carteira digital: campos especializados para produtos financeiros e seguros de carteira</li> </ul>"},{"location":"produtos/willbank_carteira/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/willbank_carteira/#dados-essenciais","title":"Dados Essenciais","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaWillbankCarteira</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 UUID da parcela <code>transactionid</code> Recomendado \u2705 transactionid <code>number</code> Sim \u2705 N\u00famero da parcela <code>status</code> Sim \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u2705 Data de estorno <p>Especificidades do Willbank Carteira</p> <ul> <li>Foco em carteira digital: \u00fanico produto com campos espec\u00edficos de produtos financeiros (ProductKey/ProductName)</li> </ul>"},{"location":"produtos/willbank_celular/","title":"Willbank Celular","text":""},{"location":"produtos/willbank_celular/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O produto Willbank Celular extrai dados de duas collections no MongoDB espec\u00edficas para seguros de aparelhos celulares, aplica transforma\u00e7\u00f5es especializadas (incluindo dados de dispositivo, car\u00eancia e m\u00faltiplas comiss\u00f5es) e carrega em uma \u00fanica tabela Postgres. Suporta atualiza\u00e7\u00f5es incremental, full e din\u00e2mica baseada em modifica\u00e7\u00f5es.</p>"},{"location":"produtos/willbank_celular/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.willbankcelular</code> (implementa\u00e7\u00e3o) e <code>implementations.willbankcelularparcelas</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_willbank_celular</code></li> </ul>"},{"location":"produtos/willbank_celular/#singularidades","title":"Singularidades","text":"<p>Caracter\u00edsticas Espec\u00edficas de Celular Willbank</p> <ul> <li>Merge : Utiliza <code>APIsAuxiliares_ParcelaUUID</code> \u2194 <code>uuidInstallment</code> para merge (n\u00e3o uuid_bilhete)</li> <li>APIs Auxiliares: campos espec\u00edficos Kakau com Brand, Model, IMEI e status de dispositivos</li> </ul>"},{"location":"produtos/willbank_celular/#funcionalidades-especiais","title":"Funcionalidades Especiais","text":""},{"location":"produtos/willbank_celular/#merge-diferenciado-por-parcelauuid","title":"Merge Diferenciado por ParcelaUUID","text":"Source code in pipeline_willbank_celular_funcoes.py <pre><code># Merge diferenciado - \u00daNICO produto que n\u00e3o usa uuid_bilhete\ndf_fim = df_info.merge(df_parcelas, \n                      left_on='info_APIsAuxiliares_ParcelaUUID',\n                      right_on='uuidInstallment', \n                      how='outer')\n\n# Processamento simples de array Parcelas (n\u00e3o Multibrick)\ndf = df.explode('parcelas', ignore_index=True)\ndf2= pd.json_normalize(df[\"parcelas\"])\ndf_fim_parcelas = pd.concat([df.drop(columns=[\"parcelas\"]), df2], axis=1)\n\n# Valor espec\u00edfico do campo Preco\ndf_fim_parcelas['VALOR_PARCELA'] = fc.converter_coluna_para_numerico(df_fim_parcelas, 'Preco')\ndf_fim_parcelas['VALOR_TARIFARIO'] = round((df_fim_parcelas['VALOR_PARCELA'] / (107.38))*100,2)\n</code></pre>"},{"location":"produtos/willbank_celular/#normalizacao-de-caracteres-especiais","title":"Normaliza\u00e7\u00e3o de Caracteres Especiais","text":"<p>Processamento \u00fanico para caracteres Unicode:</p> <pre><code># Normaliza\u00e7\u00e3o NFKD para caracteres especiais\ndf_schema = SchemaWillCelular.df_to_schema()\ncolunas_str_schema = df_schema.loc[df_schema.tipo_pandera == 'str','coluna'].to_list()\nfor col in colunas_str_schema:\n    if col in df_info.columns:\n        df_info[col] = (\n            df_info[col]\n            .astype(str)\n            .str.normalize('NFKD')\n            .str.encode('ascii', 'ignore')\n            .str.decode('utf-8')\n        )\n</code></pre>"},{"location":"produtos/willbank_celular/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":""},{"location":"produtos/willbank_celular/#dados-essenciais","title":"Dados Essenciais","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaWillCelular</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 UUID da parcela (usado no merge) <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>numero</code> Sim \u2705 N\u00famero da parcela <code>status</code> Sim \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio <code>data_inicio_vigencia</code> Sim \u2705 <code>data_fim_vigencia</code> Sim \u2705 <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim (relevante se houver estorno) \u274c Data de estorno <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaWillCelular</code>. </p>"},{"location":"produtos/xp_card/","title":"XP Card","text":""},{"location":"produtos/xp_card/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Pipeline ETL especializado para processamento de dados de seguros de cart\u00e3o da XP Investimentos, realizando extra\u00e7\u00e3o do MongoDB e carregamento no PostgreSQL. </p>"},{"location":"produtos/xp_card/#especificacoes","title":"Especifica\u00e7\u00f5es","text":"<ul> <li>Fonte: MongoDB (produ\u00e7\u00e3o)  </li> <li>Collections: <code>implementations.xpcard</code>(implementa\u00e7\u00e3o) e <code>implementations.xpcardinstallments</code> (parcelas)</li> <li>Destino: Tabela Postgres <code>innoveo_kovr_ap</code></li> </ul>"},{"location":"produtos/xp_card/#singularidades-do-produto","title":"Singularidades do Produto","text":"<p>Caracter\u00edsticas \u00danicas</p> <ul> <li>M\u00faltiplas Comiss\u00f5es: Sistema diferenciado com 3 tipos de comiss\u00e3o</li> <li>Projection Externa: Utiliza arquivo JSON espec\u00edfico para campos de extra\u00e7\u00e3o</li> </ul>"},{"location":"produtos/xp_card/#funcionalidades-especiais","title":"Funcionalidades Especiais","text":""},{"location":"produtos/xp_card/#projection-externa","title":"Projection Externa","text":"<p>Produto com arquivo JSON de proje\u00e7\u00e3o - controle externo de campos:</p> Source code in pipeline_xp_card_funcoes.py <pre><code>def carregar_projection():\n    pasta_atual = Path(__file__).parent\n    caminho_arquivo = pasta_atual / \"projection.json\"\n\n    with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n        campos = json.load(f)   # lista de campos\n    projection = {campo: 1 for campo in campos}\n    return projection\n\n# Uso na gera\u00e7\u00e3o de queries\nprojection = carregar_projection()\n</code></pre>"},{"location":"produtos/xp_card/#gerenciamento-avancado-de-indices","title":"Gerenciamento Avan\u00e7ado de \u00cdndices","text":"<p>Sistema de \u00edndices:</p> Source code in pipeline_xp_card_funcoes.py <pre><code># \u00cdndices espec\u00edficos definidos\nINDEX_TABELA_BANCO = {\n    f'idx_{NM_TABELA_BANCO}_uuid_bilhete': 'uuid_bilhete',\n    f'idx_{NM_TABELA_BANCO}_bilhete': 'info_numeroproposta',\n    f'idx_{NM_TABELA_BANCO}_data_pagamento': 'data_pagamento',\n    f'idx_{NM_TABELA_BANCO}_data_vencimento': 'data_vencimento'\n}\n</code></pre>"},{"location":"produtos/xp_card/#checklist-de-colunas-obrigatorias","title":"Checklist de Colunas Obrigat\u00f3rias","text":"Coluna Obrigat\u00f3ria Presente em <code>SchemaXpCard</code> Observa\u00e7\u00f5es <code>uuid_bilhete</code> Sim \u2705 Identificador do bilhete (UUID) <code>uuidinstallment</code> Sim \u2705 Identificador da parcela (UUID) <code>transactionid</code> Recomendado \u2705 Identificador de transa\u00e7\u00e3o da parcela <code>number</code> Sim \u2705 N\u00famero da parcela <code>status</code> Sim \u2705 Status da parcela <code>valor_parcela</code> Sim \u2705 Valor da parcela <code>valor_tarifario</code> Sim \u2705 Valor tarif\u00e1rio calculado <code>data_inicio_vigencia</code> Sim \u2705 Baseado em PolicyStartDate <code>data_fim_vigencia</code> Sim \u2705 Baseado em PolicyExpirationDate <code>data_vencimento</code> Sim \u2705 Data de vencimento da parcela <code>data_pagamento</code> Sim \u2705 Data de pagamento da parcela <code>data_cancelamento</code> Sim \u2705 Data de cancelamento, se aplic\u00e1vel <code>data_estorno</code> Sim \u2705 Data de estorno (ChargeBackDate)"},{"location":"produtos/xp_card/#particularidades-tecnicas","title":"Particularidades T\u00e9cnicas","text":"<ul> <li>Projection Externa: Produto que utiliza arquivo <code>projection.json</code> para definir campos de extra\u00e7\u00e3o</li> </ul> <p>Observa\u00e7\u00e3o sobre Schema</p> <p>Todas as colunas listadas como \"Sim\" devem estar sempre presentes no <code>SchemaXpCard</code>. </p>"}]}